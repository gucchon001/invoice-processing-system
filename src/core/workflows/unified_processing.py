"""
çµ±ä¸€è«‹æ±‚æ›¸å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

OCRãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸ
å…±é€šå‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import logging
import time
import uuid
import json
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, List, Optional, Union, Callable
from pathlib import Path
import asyncio

from core.services.invoice_validator import InvoiceValidator
from core.services.unified_prompt_manager import UnifiedPromptManager, PromptSelector
from infrastructure.ui.validation_display import ValidationDisplay, BatchValidationDisplay
from infrastructure.ai.gemini_helper import GeminiAPIManager
from infrastructure.database.database import DatabaseManager
# LocalFileAdapteré–¢é€£ã¯å‰Šé™¤ï¼ˆUnifiedWorkflowEngineã«çµ±åˆæ¸ˆã¿ï¼‰
from core.models.workflow_models import ProcessingMode, ProcessingStatus

logger = logging.getLogger(__name__)

def get_jst_now():
    """JSTï¼ˆæ—¥æœ¬æ¨™æº–æ™‚ï¼‰ã®ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—"""
    jst = timezone(timedelta(hours=9))  # JST = UTC+9
    return datetime.now(jst).isoformat()

class UnifiedProcessingWorkflow:
    """çµ±ä¸€å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, 
                 gemini_helper: GeminiAPIManager,
                 database_manager: DatabaseManager,
                 prompts_dir: str = "prompts"):
        """
        ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        
        Args:
            gemini_helper: Gemini AIå‡¦ç†ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
            database_manager: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
            prompts_dir: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.gemini_helper = gemini_helper
        self.database_manager = database_manager
        
        # å…±é€šã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self.validator = InvoiceValidator()
        self.prompt_manager = UnifiedPromptManager(prompts_dir)
        self.prompt_selector = PromptSelector(self.prompt_manager)
        self.display = ValidationDisplay()
        self.batch_display = BatchValidationDisplay()
        
        # å‡¦ç†çŠ¶æ…‹ç®¡ç†
        self.active_sessions = {}
        self.processing_callbacks = []
    
    def register_progress_callback(self, callback: Callable[[str, int, int, str], None]):
        """é€²æ—é€šçŸ¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®ç™»éŒ²"""
        self.processing_callbacks.append(callback)
    
    def notify_progress(self, session_id: str, current: int, total: int, message: str = ""):
        """é€²æ—é€šçŸ¥ã®é€ä¿¡"""
        for callback in self.processing_callbacks:
            try:
                callback(session_id, current, total, message)
            except Exception as e:
                logger.error(f"é€²æ—é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def process_single_file(self, 
                                file_data: bytes,
                                filename: str,
                                mode: str = ProcessingMode.UPLOAD,
                                prompt_key: str = None,
                                validation_config: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
        
        Args:
            file_data: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            prompt_key: ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            validation_config: æ¤œè¨¼è¨­å®š
            
        Returns:
            å‡¦ç†çµæœè¾æ›¸
        """
        session_id = str(uuid.uuid4())
        start_time = time.time()  # å‡¦ç†æ™‚é–“æ¸¬å®šé–‹å§‹
        
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
            await self._start_session(session_id, mode, [filename])
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæº–å‚™
            if not prompt_key:
                prompt_key = self.prompt_selector.get_recommended_prompt(mode)
            
            system_prompt, user_prompt = self.prompt_manager.format_prompt_for_gemini(
                prompt_key, {"filename": filename}
            )
            
            # AIå‡¦ç†å®Ÿè¡Œ
            self.notify_progress(session_id, 1, 3, "AIè§£æä¸­...")
            
            # çµ±ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµåˆ
            combined_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # GeminiAPIManagerã®ç›´æ¥å‘¼ã³å‡ºã—ï¼ˆä¸­é–“ãƒ¬ã‚¤ãƒ¤ãƒ¼å‰Šé™¤ï¼‰
            ai_result = await asyncio.to_thread(
                self.gemini_helper.analyze_pdf_content,
                file_data,
                combined_prompt
            )
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            self.notify_progress(session_id, 2, 3, "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ä¸­...")
            
            validation_result = self.validator.validate_invoice_data(
                ai_result, 
                strict_mode=validation_config.get('strict_mode', False) if validation_config else False
            )
            
            # çµæœã®çµ„ã¿ç«‹ã¦
            self.notify_progress(session_id, 3, 3, "å®Œäº†")
            
            # å‡¦ç†æ™‚é–“è¨ˆç®—
            processing_time = time.time() - start_time
            
            result = {
                'session_id': session_id,
                'filename': filename,
                'mode': mode,
                'ai_result': ai_result,
                'validation': validation_result,
                'prompt_used': prompt_key,
                'processed_at': get_jst_now(),
                'processing_time': processing_time,  # å‡¦ç†æ™‚é–“ã‚’è¿½åŠ 
                'status': ProcessingStatus.COMPLETED,
                'success': True  # æˆåŠŸãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
            }
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼ˆãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ï¼‰
            if mode == ProcessingMode.OCR_TEST:
                await self._save_ocr_test_result(session_id, result)
            elif mode in [ProcessingMode.UPLOAD, ProcessingMode.BATCH]:
                # UPLOADã¨BATCHã®ä¸¡æ–¹ã§çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¿å­˜ã‚’å®Ÿè¡Œ
                await self._save_upload_result(session_id, result)
            
            await self._complete_session(session_id, result)
            
            return result
            
        except Exception as e:
            logger.error(f"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            logger.exception(f"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†è©³ç´°ã‚¨ãƒ©ãƒ¼:")  # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚å‡ºåŠ›
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²
            processing_time = time.time() - start_time
            
            error_result = {
                'session_id': session_id,
                'filename': filename,
                'error': str(e),
                'error_details': f"Type: {type(e).__name__}, Message: {str(e)}",
                'status': ProcessingStatus.FAILED,
                'processed_at': get_jst_now(),
                'processing_time': processing_time,  # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å‡¦ç†æ™‚é–“ã‚’è¿½åŠ 
                'success': False  # å¤±æ•—ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
            }
            
            await self._fail_session(session_id, error_result)
            return error_result
    
    def process_batch(self, 
                     files_data: List[Dict[str, Any]],
                     mode: str = ProcessingMode.BATCH,
                     prompt_key: str = None,
                     include_validation: bool = True,
                     validation_config: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆåŒæœŸç‰ˆï¼‰
        
        Args:
            files_data: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            prompt_key: ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            include_validation: æ¤œè¨¼å®Ÿè¡Œãƒ•ãƒ©ã‚°
            validation_config: æ¤œè¨¼è¨­å®š
            
        Returns:
            ãƒãƒƒãƒå‡¦ç†çµæœè¾æ›¸
        """
        # éåŒæœŸå‡¦ç†ã‚’åŒæœŸçš„ã«å®Ÿè¡Œ
        import asyncio
        
        # Streamlitç’°å¢ƒã§ã®éåŒæœŸå‡¦ç†å¯¾å¿œ
        try:
            # æ—¢å­˜ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒã‚ã‚‹å ´åˆã¯æ–°ã—ã„ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(
                self.process_batch_files(files_data, mode, prompt_key, validation_config)
            )
            loop.close()
            return result
        except Exception as e:
            logger.error(f"åŒæœŸãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªåŒæœŸå‡¦ç†
            return self._process_batch_sync(files_data, mode, prompt_key, include_validation, validation_config)
    
    def _process_batch_sync(self, 
                           files_data: List[Dict[str, Any]],
                           mode: str = ProcessingMode.BATCH,
                           prompt_key: str = None,
                           include_validation: bool = True,
                           validation_config: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        åŒæœŸçš„ãªãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        
        Args:
            files_data: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            prompt_key: ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            include_validation: æ¤œè¨¼å®Ÿè¡Œãƒ•ãƒ©ã‚°
            validation_config: æ¤œè¨¼è¨­å®š
            
        Returns:
            ãƒãƒƒãƒå‡¦ç†çµæœè¾æ›¸
        """
        session_id = str(uuid.uuid4())
        
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ï¼ˆåŒæœŸç‰ˆï¼‰
            filenames = [f['filename'] for f in files_data]
            self._start_session_sync(session_id, mode, filenames)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæº–å‚™
            if not prompt_key:
                prompt_key = self.prompt_selector.get_recommended_prompt(mode)
            
            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †æ¬¡å‡¦ç†
            results = []
            total_files = len(files_data)
            
            for i, file_info in enumerate(files_data, 1):
                try:
                    self.notify_progress(
                        session_id, i, total_files, 
                        f"å‡¦ç†ä¸­: {file_info['filename']}"
                    )
                    
                    # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’åŒæœŸå®Ÿè¡Œ
                    result = self._process_single_file_sync(
                        file_info['data'],
                        file_info['filename'],
                        mode,
                        prompt_key,
                        include_validation,
                        validation_config
                    )
                    
                    results.append(result)
                    
                except Exception as e:
                    logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_info['filename']} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    results.append({
                        'filename': file_info['filename'],
                        'error': str(e),
                        'status': ProcessingStatus.FAILED,
                        'success': False,
                        'processing_time': 0
                    })
            
            # ãƒãƒƒãƒçµæœé›†è¨ˆ
            successful_files = sum(1 for r in results if r.get('success', False))
            failed_files = total_files - successful_files
            total_processing_time = sum(r.get('processing_time', 0) for r in results)
            
            batch_result = {
                'session_id': session_id,
                'mode': mode,
                'total_files': total_files,
                'successful_files': successful_files,
                'failed_files': failed_files,
                'total_processing_time': total_processing_time,
                'results': results,
                'prompt_used': prompt_key,
                'processed_at': get_jst_now(),
                'status': ProcessingStatus.COMPLETED
            }
            
            self._complete_session_sync(session_id, batch_result)
            return batch_result
            
        except Exception as e:
            logger.error(f"åŒæœŸãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            error_result = {
                'session_id': session_id,
                'error': str(e),
                'status': ProcessingStatus.FAILED,
                'processed_at': get_jst_now()
            }
            
            self._fail_session_sync(session_id, error_result)
            return error_result

    async def process_batch_files(self, 
                                files_data: List[Dict[str, Any]],
                                mode: str = ProcessingMode.BATCH,
                                prompt_key: str = None,
                                validation_config: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        
        Args:
            files_data: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            prompt_key: ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            validation_config: æ¤œè¨¼è¨­å®š
            
        Returns:
            ãƒãƒƒãƒå‡¦ç†çµæœè¾æ›¸
        """
        session_id = str(uuid.uuid4())
        
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
            filenames = [f['filename'] for f in files_data]
            await self._start_session(session_id, mode, filenames)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæº–å‚™
            if not prompt_key:
                prompt_key = self.prompt_selector.get_recommended_prompt(mode)
            
            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †æ¬¡å‡¦ç†
            results = []
            total_files = len(files_data)
            
            for i, file_info in enumerate(files_data, 1):
                try:
                    self.notify_progress(
                        session_id, i, total_files, 
                        f"å‡¦ç†ä¸­: {file_info['filename']}"
                    )
                    
                    # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’å‘¼ã³å‡ºã—
                    result = await self.process_single_file(
                        file_info['data'],
                        file_info['filename'],
                        mode,
                        prompt_key,
                        validation_config
                    )
                    
                    results.append(result)
                    
                except Exception as e:
                    logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_info['filename']} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    results.append({
                        'filename': file_info['filename'],
                        'error': str(e),
                        'status': ProcessingStatus.FAILED,
                        'success': False,  # å¤±æ•—ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
                        'processing_time': 0  # å‡¦ç†æ™‚é–“ã‚‚è¿½åŠ 
                    })
            
            # ãƒ‡ãƒãƒƒã‚°: å®Ÿéš›ã®resultsãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
            logger.info(f"ğŸ” ãƒãƒƒãƒçµæœé›†è¨ˆãƒ‡ãƒãƒƒã‚° - ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
            for i, r in enumerate(results):
                logger.info(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«{i+1}: {r.get('filename', 'N/A')}")
                logger.info(f"   - status: {r.get('status', 'N/A')}")
                logger.info(f"   - success: {r.get('success', 'N/A')}")
                logger.info(f"   - error: {r.get('error', 'ãªã—')}")
                logger.info(f"   - å…¨ã‚­ãƒ¼: {list(r.keys())}")
            
            # çµ±ä¸€ã•ã‚ŒãŸé›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯ï¼ˆsuccessã‚­ãƒ¼ã§åˆ¤å®šï¼‰
            successful_files = sum(1 for r in results if r.get('success', False))
            failed_files = total_files - successful_files
            total_processing_time = sum(r.get('processing_time', 0) for r in results)
            
            batch_result = {
                'session_id': session_id,
                'mode': mode,
                'total_files': total_files,
                'successful_files': successful_files,
                'failed_files': failed_files,
                'total_processing_time': total_processing_time,
                'results': results,
                'prompt_used': prompt_key,
                'processed_at': get_jst_now(),
                'status': ProcessingStatus.COMPLETED
            }
            
            await self._complete_session(session_id, batch_result)
            return batch_result
            
        except Exception as e:
            logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            error_result = {
                'session_id': session_id,
                'error': str(e),
                'status': ProcessingStatus.FAILED,
                'processed_at': get_jst_now()
            }
            
            await self._fail_session(session_id, error_result)
            return error_result
        
    def _extract_json_from_raw_text(self, raw_text: str) -> Optional[Dict[str, Any]]:
        """
        raw_textãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰JSONãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Args:
            raw_text: Geminiã‹ã‚‰ã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆMarkdownå½¢å¼ã®å¯èƒ½æ€§ï¼‰
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸJSONãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯ None
        """
        import re
        import json
        
        try:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ```json ï½ ``` ãƒ–ãƒ­ãƒƒã‚¯
            json_match = re.search(r'```json\s*\n(.*?)\n```', raw_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as e:
                    logger.error(f"JSONãƒ‘ãƒ¼ã‚¹ ã‚¨ãƒ©ãƒ¼ (ãƒ‘ã‚¿ãƒ¼ãƒ³1): {e}")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ```ï½``` ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆjsonæŒ‡å®šãªã—ï¼‰
            code_match = re.search(r'```\s*\n(.*?)\n```', raw_text, re.DOTALL)
            if code_match:
                potential_json = code_match.group(1).strip()
                # JSONã£ã½ã„ã‹ãƒã‚§ãƒƒã‚¯
                if potential_json.startswith('{') and potential_json.endswith('}'):
                    try:
                        return json.loads(potential_json)
                    except json.JSONDecodeError as e:
                        logger.error(f"JSONãƒ‘ãƒ¼ã‚¹ ã‚¨ãƒ©ãƒ¼ (ãƒ‘ã‚¿ãƒ¼ãƒ³2): {e}")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: { ï½ } ã®æœ€åˆã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            brace_match = re.search(r'\{.*?\}', raw_text, re.DOTALL)
            if brace_match:
                try:
                    return json.loads(brace_match.group(0))
                except json.JSONDecodeError as e:
                    logger.error(f"JSONãƒ‘ãƒ¼ã‚¹ ã‚¨ãƒ©ãƒ¼ (ãƒ‘ã‚¿ãƒ¼ãƒ³3): {e}")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: ç›´æ¥JSONæ–‡å­—åˆ—ã¨ã—ã¦è§£æ
            try:
                return json.loads(raw_text)
            except json.JSONDecodeError:
                pass
            
            logger.warning("raw_textã‹ã‚‰JSONã®æŠ½å‡ºã«å¤±æ•—: èªè­˜å¯èƒ½ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
            
        except Exception as e:
            logger.error(f"JSONæŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def _start_session(self, session_id: str, mode: str, filenames: List[str]):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹å‡¦ç†"""
        self.active_sessions[session_id] = {
            'mode': mode,
            'filenames': filenames,
            'started_at': get_jst_now(),
            'status': ProcessingStatus.IN_PROGRESS
        }
        
        logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {session_id} (ãƒ¢ãƒ¼ãƒ‰: {mode}, ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(filenames)})")
    
    async def _complete_session(self, session_id: str, result: Dict[str, Any]):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†å‡¦ç†"""
        if session_id in self.active_sessions:
            self.active_sessions[session_id]['status'] = ProcessingStatus.COMPLETED
            self.active_sessions[session_id]['completed_at'] = get_jst_now()
            self.active_sessions[session_id]['result'] = result
        
        logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†: {session_id}")
    
    async def _fail_session(self, session_id: str, error_result: Dict[str, Any]):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤±æ•—å‡¦ç†"""
        if session_id in self.active_sessions:
            self.active_sessions[session_id]['status'] = ProcessingStatus.FAILED
            self.active_sessions[session_id]['failed_at'] = get_jst_now()
            self.active_sessions[session_id]['error'] = error_result
        
        logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤±æ•—: {session_id}")
    
    async def _save_ocr_test_result(self, session_id: str, result: Dict[str, Any]):
        """OCRãƒ†ã‚¹ãƒˆçµæœã®ä¿å­˜"""
        try:
            # OCRãƒ†ã‚¹ãƒˆç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
            pass  # å®Ÿè£…ã¯æ—¢å­˜ã®OCRãƒ†ã‚¹ãƒˆä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
        except Exception as e:
            logger.error(f"OCRãƒ†ã‚¹ãƒˆçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _save_upload_result(self, session_id: str, result: Dict[str, Any]):
        """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœã®ä¿å­˜ï¼ˆOCRãƒ†ã‚¹ãƒˆç›¸å½“ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼‰"""
        try:
            logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜é–‹å§‹: {session_id}")
            
            # OCRãƒ†ã‚¹ãƒˆã¨åŒæ§˜ã®å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            ai_result = result.get('ai_result', {})
            validation = result.get('validation', {})
            filename = result.get('filename', 'N/A')
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®æ¨å®šï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—ã¯å›°é›£ãªãŸã‚æ¨å®šå€¤ã‚’ä½¿ç”¨ï¼‰
            estimated_file_size = len(str(ai_result)) * 100  # AIçµæœã‚µã‚¤ã‚ºã‹ã‚‰æ¨å®š
            
            # çµæœãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆinvoicesãƒ†ãƒ¼ãƒ–ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæº–æ‹ ï¼‰
            result_data = {
                "user_email": "y-haraguchi@tomonokai-corp.com",  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼
                "status": "processed",
                "file_name": filename,
                "file_id": f"unified_workflow_{session_id}",  # çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”¨ã®file_idç”Ÿæˆ
                "session_id": session_id,
                "file_size": estimated_file_size,
                "issuer_name": ai_result.get("issuer"),
                "recipient_name": ai_result.get("payer"),
                "invoice_number": ai_result.get("main_invoice_number"),
                "registration_number": ai_result.get("t_number"),
                "currency": ai_result.get("currency"),
                "total_amount_tax_included": ai_result.get("amount_inclusive_tax"),
                "total_amount_tax_excluded": ai_result.get("amount_exclusive_tax"),
                "issue_date": ai_result.get("issue_date"),
                "due_date": ai_result.get("due_date"),
                "key_info": ai_result.get("key_info"),
                "raw_response": ai_result,
                "extracted_data": ai_result,
                "is_valid": validation.get("is_valid", True),
                "validation_errors": validation.get("errors", []),
                "validation_warnings": validation.get("warnings", []),
                "completeness_score": self._calculate_completeness_score(ai_result),
                "processing_time": result.get('processing_time', 0),
                "gemini_model": "gemini-2.0-flash-exp"
            }
            
            logger.info(f"ä¿å­˜ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {filename} (é€šè²¨: {result_data['currency']})")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ocr_test_resultsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
            if self.database_manager:
                try:
                    import streamlit as st
                    service_key = st.secrets["database"]["supabase_service_key"]
                    supabase_url = st.secrets["database"]["supabase_url"]
                    
                    from supabase import create_client
                    service_supabase = create_client(supabase_url, service_key)
                    
                    logger.info(f"Service Role Keyä½¿ç”¨ã§invoicesãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜é–‹å§‹")
                    
                    # çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœã‚’æœ¬ç•ªinvoicesãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
                    result_response = service_supabase.table("invoices").insert(result_data).execute()
                    
                    if result_response.data:
                        result_id = result_response.data[0]["id"]
                        
                        # æ˜ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                        await self._save_line_items(service_supabase, result_id, ai_result.get("line_items", []))
                        
                        logger.info(f"âœ… invoicesãƒ†ãƒ¼ãƒ–ãƒ«ä¿å­˜æˆåŠŸ: {result_id}")
                    else:
                        logger.error(f"âŒ invoicesãƒ†ãƒ¼ãƒ–ãƒ«ä¿å­˜å¤±æ•—: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãªã—")
                    
                except Exception as db_error:
                    logger.error(f"âŒ Service Role Keyä½¿ç”¨å¤±æ•—: {db_error}")
                    logger.info("é€šå¸¸ã‚­ãƒ¼ã§ã®invoicesãƒ†ãƒ¼ãƒ–ãƒ«ä¿å­˜ã¯æ¨©é™ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                    # RLS ã‚¨ãƒ©ãƒ¼ãŒç¢ºå®Ÿã«ç™ºç”Ÿã™ã‚‹ãŸã‚ã€é€šå¸¸ã‚­ãƒ¼ã§ã®è©¦è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
                    
        except Exception as e:
            logger.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ç‰¹åˆ¥ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if "does not exist" in str(e) or "relation" in str(e):
                logger.info("æœ¬ç•ªç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæœªä½œæˆã®ãŸã‚ã€çµæœä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            else:
                logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜è©³ç´°ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _save_line_items(self, supabase_client, result_id: str, line_items: List[Dict[str, Any]]):
        """æ˜ç´°ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜"""
        try:
            for i, item in enumerate(line_items, 1):
                # ç¨ç‡ãƒ‡ãƒ¼ã‚¿ã®æ•°å€¤å¤‰æ›ï¼ˆ"10%" â†’ 10.0ï¼‰
                tax_rate = item.get("tax")
                if tax_rate and isinstance(tax_rate, str):
                    try:
                        if "%" in tax_rate:
                            tax_rate = float(tax_rate.replace("%", "").strip())
                        else:
                            tax_rate = float(tax_rate)
                    except (ValueError, AttributeError):
                        tax_rate = None
                
                # JSTæ™‚é–“å–å¾—
                jst_now = get_jst_now()
                
                line_item_data = {
                    "invoice_id": result_id,
                    "line_number": i,
                    "item_description": item.get("description"),
                    "quantity": item.get("quantity"),
                    "unit_price": item.get("unit_price"),
                    "amount": item.get("amount"),
                    "tax_rate": tax_rate,
                    "created_at": jst_now,
                    "updated_at": jst_now
                }
                
                supabase_client.table("invoice_line_items").insert(line_item_data).execute()
                
        except Exception as e:
            logger.error(f"æ˜ç´°ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _calculate_completeness_score(self, ai_result: Dict[str, Any]) -> float:
        """å®Œå…¨æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆOCRãƒ†ã‚¹ãƒˆã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
        try:
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆï¼‰
            required_fields = ["issuer", "amount_inclusive_tax", "currency"]
            
            # é‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            important_fields = ["payer", "main_invoice_number", "issue_date"]
            
            # ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            optional_fields = ["t_number", "amount_exclusive_tax", "due_date", "line_items", "key_info"]
            
            score = 0
            total_weight = 100
            
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆ60ç‚¹æº€ç‚¹ï¼‰
            required_weight = 60
            for field in required_fields:
                value = ai_result.get(field)
                if self._is_valid_field_value(value):
                    score += required_weight / len(required_fields)
            
            # é‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆ30ç‚¹æº€ç‚¹ï¼‰
            important_weight = 30
            for field in important_fields:
                value = ai_result.get(field)
                if self._is_valid_field_value(value):
                    score += important_weight / len(important_fields)
            
            # ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆ10ç‚¹æº€ç‚¹ï¼‰
            optional_weight = 10
            for field in optional_fields:
                value = ai_result.get(field)
                if self._is_valid_field_value(value):
                    score += optional_weight / len(optional_fields)
            
            return min(100.0, max(0.0, score))
            
        except Exception as e:
            logger.error(f"å®Œå…¨æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def _is_valid_field_value(self, value) -> bool:
        """ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯"""
        if value is None:
            return False
        if isinstance(value, str) and value.strip() == "":
            return False
        if isinstance(value, (int, float)) and value == 0:
            return False
        if isinstance(value, list) and len(value) == 0:
            return False
        if isinstance(value, dict) and len(value) == 0:
            return False
        return True
    
    def get_session_status(self, session_id: str) -> Optional[Dict[str, Any]]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å–å¾—"""
        return self.active_sessions.get(session_id)
    
    def cancel_session(self, session_id: str) -> bool:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        if session_id in self.active_sessions:
            self.active_sessions[session_id]['status'] = ProcessingStatus.CANCELLED
            self.active_sessions[session_id]['cancelled_at'] = get_jst_now()
            logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒ³ã‚»ãƒ«: {session_id}")
            return True
        return False
    
    def cleanup_old_sessions(self, max_age_hours: int = 24):
        """å¤ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        jst = timezone(timedelta(hours=9))
        current_time = datetime.now(jst)
        to_remove = []
        
        for session_id, session_data in self.active_sessions.items():
            session_age = current_time - session_data['started_at']
            if session_age.total_seconds() > max_age_hours * 3600:
                to_remove.append(session_id)
        
        for session_id in to_remove:
            del self.active_sessions[session_id]
            logger.info(f"å¤ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤: {session_id}")
        
        return len(to_remove)

class WorkflowDisplayManager:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¡¨ç¤ºç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, workflow: UnifiedProcessingWorkflow):
        self.workflow = workflow
        self.display = ValidationDisplay()
        self.batch_display = BatchValidationDisplay()
        
        # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®ç™»éŒ²ï¼ˆç„¡åŠ¹åŒ– - ãƒ¡ã‚¤ãƒ³ã§ç®¡ç†ï¼‰
        # self.workflow.register_progress_callback(self._handle_progress_update)
    
    def _handle_progress_update(self, session_id: str, current: int, total: int, message: str):
        """é€²æ—æ›´æ–°ã®å‡¦ç†"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ä½¿ç”¨
        import streamlit as st
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ä¸€æ„ã‚­ãƒ¼ã‚’ç”Ÿæˆ
        progress_key = f"progress_{session_id}"
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ç®¡ç†
        if progress_key not in st.session_state:
            st.session_state[progress_key] = st.empty()
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
        progress_container = st.session_state[progress_key]
        progress_value = current / total if total > 0 else 0
        
        with progress_container.container():
            st.progress(progress_value, text=message)
    
    def display_single_result(self, result: Dict[str, Any]):
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«çµæœã®è¡¨ç¤º"""
        import streamlit as st
        
        # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        if result.get('error'):
            st.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {result['error']}")
            st.error(f"ğŸ“‹ ã‚¨ãƒ©ãƒ¼è©³ç´°: {result.get('error_details', 'è©³ç´°ä¸æ˜')}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ã¿è¡¨ç¤º
            file_info = {
                'name': result.get('filename', 'N/A'),
                'size': 'ã‚¨ãƒ©ãƒ¼ã®ãŸã‚å–å¾—ä¸å¯',
                'processed_at': result.get('processed_at', 'N/A'),
                'processing_time': f"{result.get('processing_time', 0):.2f}ç§’" if result.get('processing_time') else 'N/A'
            }
            self.display.display_file_info(file_info)
            return
        
        # æ­£å¸¸å‡¦ç†ã®å ´åˆ
        status = result.get('status', 'unknown')
        if status != 'completed':
            st.warning(f"âš ï¸ å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
        
        # AIçµæœã®è¡¨ç¤º
        if result.get('ai_result'):
            st.subheader("ğŸ¤– AIè§£æçµæœ")
            
            ai_result = result['ai_result']
            
            # çµæœãŒç©ºã®å ´åˆ
            if not ai_result or ai_result == {}:
                st.warning("âš ï¸ AIè§£æçµæœãŒç©ºã§ã™ã€‚PDFã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("è«‹æ±‚å…ƒ", ai_result.get('issuer', 'N/A'))
                with col2:
                    amount = ai_result.get('amount_inclusive_tax', 0)
                    st.metric("ç¨è¾¼é‡‘é¡", f"Â¥{amount:,}" if amount else 'N/A')
                with col3:
                    st.metric("é€šè²¨", ai_result.get('currency', 'JPY'))
                
                # è©³ç´°æƒ…å ±
                with st.expander("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿", expanded=False):
                    st.json(ai_result)
        else:
            st.warning("âš ï¸ AIè§£æçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        
        # æ¤œè¨¼çµæœã®è¡¨ç¤º
        if result.get('validation'):
            validation = result['validation']
            st.subheader("ğŸ” ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çµæœ")
            
            # è­¦å‘Šã¨ã‚¨ãƒ©ãƒ¼ã®è©³ç´°è¡¨ç¤º
            if validation.get('warnings'):
                with st.expander(f"âš ï¸ è­¦å‘Šè©³ç´°: {len(validation['warnings'])}ä»¶", expanded=True):
                    for i, warning in enumerate(validation['warnings'], 1):
                        st.warning(f"**è­¦å‘Š {i}**: {warning}")
                        
            if validation.get('errors'):
                with st.expander(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°: {len(validation['errors'])}ä»¶", expanded=True):
                    for i, error in enumerate(validation['errors'], 1):
                        st.error(f"**ã‚¨ãƒ©ãƒ¼ {i}**: {error}")
            
            if not validation.get('warnings') and not validation.get('errors'):
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼: å•é¡Œãªã—")
            
            # å¾“æ¥ã®è©³ç´°æ¤œè¨¼çµæœã‚‚è¡¨ç¤º
            self.display.display_validation_results(
                validation,
                f"è©³ç´°æ¤œè¨¼çµæœ: {result.get('filename', 'N/A')}"
            )
        
        # ag-gridå½¢å¼ã§ã®è©³ç´°è¡¨ç¤ºã‚’è¿½åŠ 
        self.display_detailed_results_with_aggrid([result])
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        ai_result = result.get('ai_result', {})
        file_info = {
            'name': result.get('filename', 'N/A'),
            'size': f"{len(str(ai_result))} bytes (ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º)" if ai_result else 'ãƒ‡ãƒ¼ã‚¿ãªã—',
            'processed_at': result.get('processed_at', 'N/A'),
            'processing_time': f"{result.get('processing_time', 0):.2f}ç§’" if result.get('processing_time') else 'N/A'
        }
        self.display.display_file_info(file_info)
    

    def display_batch_results(self, batch_result: Dict[str, Any]):
        """ãƒãƒƒãƒå‡¦ç†çµæœã®è¡¨ç¤º"""
        import streamlit as st
        
        results = batch_result.get('results', [])
        
        # ãƒãƒƒãƒã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
        self.batch_display.display_batch_summary(results)
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ç´„çµæœ
        st.subheader("ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥å‡¦ç†çµæœ")
        
        for i, result in enumerate(results, 1):
            filename = result.get('filename', f'ãƒ•ã‚¡ã‚¤ãƒ«{i}')
            status = result.get('status', 'unknown')
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¢ã‚¤ã‚³ãƒ³
            status_icon = "âœ…" if status == "completed" else "âŒ" if status == "failed" else "â³"
            
            with st.expander(f"{status_icon} {filename}", expanded=False):
                if result.get('ai_result'):
                    ai_result = result['ai_result']
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**è«‹æ±‚å…ƒ**: {ai_result.get('issuer', 'N/A')}")
                        st.write(f"**è«‹æ±‚æ›¸ç•ªå·**: {ai_result.get('main_invoice_number', 'N/A')}")
                        st.write(f"**ç™ºè¡Œæ—¥**: {ai_result.get('issue_date', 'N/A')}")
                    
                    with col2:
                        amount = ai_result.get('amount_inclusive_tax', 0)
                        st.write(f"**ç¨è¾¼é‡‘é¡**: Â¥{amount:,}" if amount else "**ç¨è¾¼é‡‘é¡**: N/A")
                        st.write(f"**é€šè²¨**: {ai_result.get('currency', 'JPY')}")
                        st.write(f"**å‡¦ç†æ™‚é–“**: {result.get('processing_time', 0):.2f}ç§’")
                    
                    # ã‚­ãƒ¼æƒ…å ±ãŒã‚ã‚‹å ´åˆ
                    key_info = ai_result.get('key_info', {})
                    if key_info:
                        st.write("**ğŸ”‘ é‡è¦æƒ…å ±**:")
                        for key, value in key_info.items():
                            st.write(f"- {key}: {value}")
                
                # æ¤œè¨¼çµæœã®è¡¨ç¤º
                if result.get('validation'):
                    validation = result['validation']
                    if validation.get('warnings'):
                        with st.expander(f"âš ï¸ è­¦å‘Š: {len(validation['warnings'])}ä»¶", expanded=False):
                            for i, warning in enumerate(validation['warnings'], 1):
                                st.warning(f"**è­¦å‘Š {i}**: {warning}")
                    if validation.get('errors'):
                        with st.expander(f"âŒ ã‚¨ãƒ©ãƒ¼: {len(validation['errors'])}ä»¶", expanded=False):
                            for i, error in enumerate(validation['errors'], 1):
                                st.error(f"**ã‚¨ãƒ©ãƒ¼ {i}**: {error}")
                    
                    # å…¨ä½“ã®æ¤œè¨¼ã‚µãƒãƒªãƒ¼
                    if validation.get('warnings') or validation.get('errors'):
                        total_issues = len(validation.get('warnings', [])) + len(validation.get('errors', []))
                        st.info(f"ğŸ“‹ æ¤œè¨¼è©³ç´°: åˆè¨ˆ {total_issues} ä»¶ã®èª²é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                
                if result.get('error'):
                    st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {result['error']}")
        
        # å…¨ä½“çµ±è¨ˆ
        st.subheader("ğŸ“Š å‡¦ç†çµ±è¨ˆ")
        successful = sum(1 for r in results if r.get('status') == 'completed')
        total_files = len(results)
        total_time = sum(r.get('processing_time', 0) for r in results)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æˆåŠŸç‡", f"{successful/total_files*100:.1f}%" if total_files > 0 else "0%")
        with col2:
            st.metric("ç·å‡¦ç†æ™‚é–“", f"{total_time:.2f}ç§’")
        with col3:
            st.metric("å¹³å‡å‡¦ç†æ™‚é–“", f"{total_time/total_files:.2f}ç§’" if total_files > 0 else "0ç§’")
        with col4:
            st.metric("ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ", f"{total_files/total_time*60:.1f}ä»¶/åˆ†" if total_time > 0 else "âˆ")

    def display_detailed_results_with_aggrid(self, results: List[Dict[str, Any]]):
        """ag-gridã‚’ä½¿ã£ãŸè©³ç´°çµæœè¡¨ç¤ºï¼ˆOCRãƒ†ã‚¹ãƒˆç›¸å½“ï¼‰"""
        import streamlit as st
        import pandas as pd
        
        try:
            from infrastructure.ui.aggrid_helper import get_aggrid_manager
            
            aggrid_manager = get_aggrid_manager()
            if not aggrid_manager:
                st.warning("ag-gridãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä»£æ›¿è¡¨ç¤ºã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                return
            
            # çµæœãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
            results_data = []
            for result in results:
                ai_result = result.get('ai_result', {})
                validation = result.get('validation', {})
                
                # å®Œå…¨æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆOCRãƒ†ã‚¹ãƒˆç›¸å½“ï¼‰
                total_fields = 10  # ä¸»è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°
                filled_fields = sum(1 for key in ['issuer', 'amount_inclusive_tax', 'currency', 'issue_date', 'main_invoice_number'] 
                                  if ai_result.get(key))
                completeness_score = (filled_fields / total_fields) * 100
                
                # ç¨è¾¼é‡‘é¡ã®å®‰å…¨ãªå¤‰æ›
                tax_included = ai_result.get("amount_inclusive_tax", 0)
                if not isinstance(tax_included, (int, float)):
                    try:
                        tax_included = float(tax_included) if tax_included else 0
                    except (ValueError, TypeError):
                        tax_included = 0
                tax_included = int(tax_included)
                
                # ã‚¨ãƒ©ãƒ¼æ•°ã¨è­¦å‘Šæ•°
                error_count = len(validation.get("errors", []))
                warning_count = len(validation.get("warnings", []))
                
                results_data.append({
                    "ãƒ•ã‚¡ã‚¤ãƒ«å": result.get('filename', 'N/A'),
                    "è«‹æ±‚å…ƒ": ai_result.get('issuer', ''),
                    "è«‹æ±‚æ›¸ç•ªå·": ai_result.get('main_invoice_number', ''),
                    "é€šè²¨": ai_result.get('currency', ''),
                    "ç¨è¾¼é‡‘é¡": tax_included,
                    "ç™ºè¡Œæ—¥": ai_result.get('issue_date', ''),
                    "æ¤œè¨¼çŠ¶æ³": "âœ… æ­£å¸¸" if validation.get('is_valid', True) else "âŒ ã‚¨ãƒ©ãƒ¼",
                    "å®Œå…¨æ€§ã‚¹ã‚³ã‚¢": round(completeness_score, 1),
                    "ã‚¨ãƒ©ãƒ¼æ•°": error_count,
                    "è­¦å‘Šæ•°": warning_count,
                    "å‡¦ç†æ™‚é–“": f"{result.get('processing_time', 0):.2f}ç§’"
                })
            
            if len(results_data) > 0:
                df = pd.DataFrame(results_data)
                
                # é¸æŠçŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
                col_grid, col_reset = st.columns([4, 1])
                with col_grid:
                    st.subheader("ğŸ“Š çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœ (ag-grid)")
                with col_reset:
                    if st.button("ğŸ”„ é¸æŠãƒªã‚»ãƒƒãƒˆ", key="reset_unified_workflow_selection"):
                        unified_key = "selected_unified_workflow_file"
                        if unified_key in st.session_state:
                            del st.session_state[unified_key]
                        st.rerun()
                
                grid_response = aggrid_manager.create_data_grid(
                    df,
                    editable=False,
                    fit_columns_on_grid_load=True,
                    selection_mode="single",
                    use_checkbox=False,
                    height=400
                )
                
                # é¸æŠã•ã‚ŒãŸè¡Œã®è©³ç´°è¡¨ç¤º
                selected_rows = aggrid_manager.get_selected_rows(grid_response)
                
                # selected_rowsã®å®‰å…¨ãªå‡¦ç†
                if hasattr(selected_rows, 'to_dict'):
                    selected_rows = selected_rows.to_dict('records')
                elif not isinstance(selected_rows, list):
                    selected_rows = []
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§é¸æŠæƒ…å ±ã‚’ç®¡ç†
                unified_key = "selected_unified_workflow_file"
                
                # æ–°ã—ã„é¸æŠãŒã‚ã‚Œã°ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                if len(selected_rows) > 0:
                    selected_row = selected_rows[0]
                    filename = selected_row["ãƒ•ã‚¡ã‚¤ãƒ«å"]
                    st.session_state[unified_key] = filename
                # é¸æŠãŒãªã‘ã‚Œã°ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å¾©å…ƒ
                elif unified_key in st.session_state:
                    filename = st.session_state[unified_key]
                else:
                    filename = None
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã®è©³ç´°è¡¨ç¤º
                if filename:
                    st.markdown(f"### ğŸ“„ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
                    
                    # è©²å½“ã™ã‚‹è©³ç´°çµæœã‚’å–å¾—
                    try:
                        selected_result = next(
                            r for r in results 
                            if r.get('filename') == filename
                        )
                    except StopIteration:
                        st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã®è©³ç´°çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                        if unified_key in st.session_state:
                            del st.session_state[unified_key]
                        selected_result = None
                    
                    # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
                    if selected_result is not None:
                        self.display_invoice_details(selected_result)
                        
        except ImportError:
            st.warning("ag-gridãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æ¨™æº–ã®DataFrameã§è¡¨ç¤ºã—ã¾ã™ã€‚")
            # ä»£æ›¿è¡¨ç¤º
            if len(results_data) > 0:
                df = pd.DataFrame(results_data)
                st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.error(f"ag-gridè¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

    def display_invoice_details(self, result: Dict[str, Any]):
        """è«‹æ±‚æ›¸è©³ç´°æƒ…å ±ã®è¡¨ç¤ºï¼ˆOCRãƒ†ã‚¹ãƒˆç›¸å½“ï¼‰"""
        import streamlit as st
        
        ai_result = result.get('ai_result', {})
        validation = result.get('validation', {})
        
        # åŸºæœ¬æƒ…å ±è¡¨ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ“‹ åŸºæœ¬æƒ…å ±")
            st.write(f"**è«‹æ±‚å…ƒ**: {ai_result.get('issuer', 'N/A')}")
            st.write(f"**è«‹æ±‚å…ˆ**: {ai_result.get('payer', 'N/A')}")
            st.write(f"**è«‹æ±‚æ›¸ç•ªå·**: {ai_result.get('main_invoice_number', 'N/A')}")
            st.write(f"**ç™ºè¡Œæ—¥**: {ai_result.get('issue_date', 'N/A')}")
            st.write(f"**æ”¯æ‰•æœŸæ—¥**: {ai_result.get('due_date', 'N/A')}")
        
        with col2:
            st.markdown("#### ğŸ’° é‡‘é¡æƒ…å ±")
            amount_inc = ai_result.get('amount_inclusive_tax', 0)
            amount_exc = ai_result.get('amount_exclusive_tax', 0)
            st.write(f"**ç¨è¾¼é‡‘é¡**: Â¥{amount_inc:,}" if amount_inc else "**ç¨è¾¼é‡‘é¡**: N/A")
            st.write(f"**ç¨æŠœé‡‘é¡**: Â¥{amount_exc:,}" if amount_exc else "**ç¨æŠœé‡‘é¡**: N/A")
            st.write(f"**é€šè²¨**: {ai_result.get('currency', 'N/A')}")
            
            # ç¨ç‡è¨ˆç®—
            if amount_inc and amount_exc and amount_inc > amount_exc:
                tax_rate = ((amount_inc - amount_exc) / amount_exc) * 100
                st.write(f"**è¨ˆç®—ç¨ç‡**: {tax_rate:.1f}%")
        
        # æ˜ç´°è¡¨ç¤º
        st.markdown("---")
        self.display_line_items(ai_result)
        
        # JSONè¡¨ç¤º
        st.markdown("---")
        st.markdown("### ğŸ“„ JSONå½¢å¼ã®AIçµæœ")
        with st.expander("è©³ç´°JSONè¡¨ç¤º", expanded=False):
            st.json(ai_result)
        
        # æ¤œè¨¼çµæœè©³ç´°
        if validation:
            st.markdown("---")
            st.markdown("### ğŸ” æ¤œè¨¼çµæœè©³ç´°")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ¤œè¨¼çŠ¶æ³", "âœ… åˆæ ¼" if validation.get('is_valid', True) else "âŒ ä¸åˆæ ¼")
            with col2:
                st.metric("ã‚¨ãƒ©ãƒ¼æ•°", len(validation.get('errors', [])))
            with col3:
                st.metric("è­¦å‘Šæ•°", len(validation.get('warnings', [])))

    def display_line_items(self, ai_result: Dict[str, Any]):
        """æ˜ç´°æƒ…å ±ã‚’ag-gridã§è¡¨ç¤ºï¼ˆOCRãƒ†ã‚¹ãƒˆç›¸å½“ï¼‰"""
        import streamlit as st
        import pandas as pd
        
        line_items = ai_result.get("line_items", [])
        if not isinstance(line_items, list):
            line_items = []
        
        if len(line_items) > 0:
            st.markdown("### ğŸ“‹ æ˜ç´°æƒ…å ±")
            line_items_df = pd.DataFrame([
                {
                    "No.": i+1,
                    "å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹å": item.get("description", ""),
                    "æ•°é‡": item.get("quantity", ""),
                    "å˜ä¾¡": item.get("unit_price", ""),
                    "é‡‘é¡": item.get("amount", ""),
                    "ç¨ç‡": item.get("tax", "")
                }
                for i, item in enumerate(line_items)
            ])
            
            # ag-gridã§æ˜ç´°è¡¨ç¤º
            try:
                from infrastructure.ui.aggrid_helper import get_aggrid_manager
                aggrid_manager = get_aggrid_manager()
                if aggrid_manager:
                    aggrid_manager.create_data_grid(
                        line_items_df,
                        editable=False,
                        fit_columns_on_grid_load=True,
                        height=200
                    )
                else:
                    st.dataframe(line_items_df, use_container_width=True)
            except ImportError:
                # ag-gridãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯æ¨™æº–è¡¨ç¤º
                st.dataframe(line_items_df, use_container_width=True)
            except Exception as e:
                st.error(f"æ˜ç´°è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.dataframe(line_items_df, use_container_width=True)
        else:
            st.info("ğŸ“‹ æ˜ç´°æƒ…å ±: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯æ˜ç´°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


# åŒæœŸå‡¦ç†ç”¨ã®æ‹¡å¼µãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆUnifiedProcessingWorkflowã‚¯ãƒ©ã‚¹ã«è¿½åŠ ï¼‰
def _add_sync_methods_to_workflow():
    """åŒæœŸå‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¯ãƒ©ã‚¹ã«å‹•çš„è¿½åŠ """
    
    def _process_single_file_sync(self, 
                                 file_data: bytes,
                                 filename: str,
                                 mode: str = ProcessingMode.UPLOAD,
                                 prompt_key: str = None,
                                 include_validation: bool = True,
                                 validation_config: Dict[str, Any] = None) -> Dict[str, Any]:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®åŒæœŸå‡¦ç†"""
        session_id = str(uuid.uuid4())
        start_time = time.time()
        
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæº–å‚™
            if not prompt_key:
                prompt_key = self.prompt_selector.get_recommended_prompt(mode)
            
            system_prompt, user_prompt = self.prompt_manager.format_prompt_for_gemini(
                prompt_key, {"filename": filename}
            )
            
            # AIå‡¦ç†å®Ÿè¡Œï¼ˆåŒæœŸï¼‰
            # çµ±ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµåˆ
            combined_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            # GeminiAPIManagerã®ç›´æ¥å‘¼ã³å‡ºã—ï¼ˆä¸­é–“ãƒ¬ã‚¤ãƒ¤ãƒ¼å‰Šé™¤ï¼‰
            ai_result = self.gemini_helper.analyze_pdf_content(
                file_data,
                combined_prompt
            )
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            validation_result = {}
            if include_validation:
                validation_result = self.validator.validate_invoice_data(
                    ai_result, 
                    strict_mode=validation_config.get('strict_mode', False) if validation_config else False
                )
            
            # å‡¦ç†æ™‚é–“è¨ˆç®—
            processing_time = time.time() - start_time
            
            result = {
                'session_id': session_id,
                'filename': filename,
                'mode': mode,
                'ai_result': ai_result,
                'validation': validation_result,
                'prompt_used': prompt_key,
                'processed_at': get_jst_now(),
                'processing_time': processing_time,
                'status': ProcessingStatus.COMPLETED,
                'success': True
            }
            
            return result
            
        except Exception as e:
            logger.error(f"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            processing_time = time.time() - start_time
            
            error_result = {
                'session_id': session_id,
                'filename': filename,
                'error': str(e),
                'error_details': f"Type: {type(e).__name__}, Message: {str(e)}",
                'status': ProcessingStatus.FAILED,
                'processed_at': get_jst_now(),
                'processing_time': processing_time,
                'success': False
            }
            
            return error_result
    
    # _process_with_gemini_sync ãƒ¡ã‚½ãƒƒãƒ‰å‰Šé™¤æ¸ˆã¿ï¼ˆç›´æ¥ GeminiAPIManager.analyze_pdf_content å‘¼ã³å‡ºã—ã«çµ±ä¸€ï¼‰
    
    def _start_session_sync(self, session_id: str, mode: str, filenames: List[str]):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹å‡¦ç†ï¼ˆåŒæœŸç‰ˆï¼‰"""
        self.active_sessions[session_id] = {
            'mode': mode,
            'filenames': filenames,
            'started_at': get_jst_now(),
            'status': ProcessingStatus.IN_PROGRESS
        }
        
        logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {session_id} (ãƒ¢ãƒ¼ãƒ‰: {mode}, ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(filenames)})")
    
    def _complete_session_sync(self, session_id: str, result: Dict[str, Any]):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†å‡¦ç†ï¼ˆåŒæœŸç‰ˆï¼‰"""
        if session_id in self.active_sessions:
            self.active_sessions[session_id]['status'] = ProcessingStatus.COMPLETED
            self.active_sessions[session_id]['completed_at'] = get_jst_now()
            self.active_sessions[session_id]['result'] = result
        
        logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†: {session_id}")
    
    def _fail_session_sync(self, session_id: str, error_result: Dict[str, Any]):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤±æ•—å‡¦ç†ï¼ˆåŒæœŸç‰ˆï¼‰"""
        if session_id in self.active_sessions:
            self.active_sessions[session_id]['status'] = ProcessingStatus.FAILED
            self.active_sessions[session_id]['failed_at'] = get_jst_now()
            self.active_sessions[session_id]['error'] = error_result
        
        logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤±æ•—: {session_id}")
    
    # ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚¯ãƒ©ã‚¹ã«å‹•çš„è¿½åŠ 
    UnifiedProcessingWorkflow._process_single_file_sync = _process_single_file_sync
    # UnifiedProcessingWorkflow._process_with_gemini_sync = _process_with_gemini_sync  # å‰Šé™¤æ¸ˆã¿
    UnifiedProcessingWorkflow._start_session_sync = _start_session_sync
    UnifiedProcessingWorkflow._complete_session_sync = _complete_session_sync
    UnifiedProcessingWorkflow._fail_session_sync = _fail_session_sync
    
# è‡ªå‹•çš„ã«ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
_add_sync_methods_to_workflow()