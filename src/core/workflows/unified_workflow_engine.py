"""
çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³

å…¨ã¦ã®è«‹æ±‚æ›¸å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’çµ±ä¸€ç®¡ç†ã™ã‚‹ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹
é‡è¤‡ã‚³ãƒ¼ãƒ‰ã®çµ±åˆã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§ã®å‘ä¸Šã‚’ç›®çš„ã¨ã™ã‚‹
40ã‚«ãƒ©ãƒ æ–°æ©Ÿèƒ½å¯¾å¿œ: å¤–è²¨æ›ç®—ãƒ»æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ»freeeé€£æºçµ±åˆ
"""

import logging
import time
from datetime import datetime
from typing import Dict, Any, Optional, Callable, List
import uuid

from core.models.workflow_models import WorkflowStatus, WorkflowProgress, WorkflowResult
from core.services.unified_prompt_manager import UnifiedPromptManager, PromptSelector
from core.services.currency_conversion_service import CurrencyConversionService  # ğŸ†• v3.0 NEW
from core.services.approval_control_service import ApprovalControlService        # ğŸ†• v3.0 NEW
from core.services.freee_integration_service import FreeeIntegrationService      # ğŸ†• v3.0 NEW
from infrastructure.ai.gemini_helper import GeminiAPIManager
from infrastructure.storage.google_drive_helper import GoogleDriveManager
from infrastructure.database.database import DatabaseManager
from utils.log_config import get_logger

logger = get_logger(__name__)

class UnifiedWorkflowEngine:
    """çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆ40ã‚«ãƒ©ãƒ æ–°æ©Ÿèƒ½å¯¾å¿œï¼‰"""
    
    def __init__(self, 
                 ai_service: GeminiAPIManager,
                 storage_service: GoogleDriveManager,
                 database_service: DatabaseManager,
                 progress_callback: Optional[Callable[[WorkflowProgress], None]] = None):
        """
        Args:
            ai_service: AIæƒ…å ±æŠ½å‡ºã‚µãƒ¼ãƒ“ã‚¹
            storage_service: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µãƒ¼ãƒ“ã‚¹
            database_service: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µãƒ¼ãƒ“ã‚¹
            progress_callback: é€²æ—é€šçŸ¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        """
        self.ai_service = ai_service
        self.storage_service = storage_service
        self.database_service = database_service
        self.progress_callback = progress_callback
        
        # çµ±ä¸€ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        self.prompt_manager = UnifiedPromptManager()
        self.prompt_selector = PromptSelector(self.prompt_manager)
        
        # ğŸ†• 40ã‚«ãƒ©ãƒ æ–°æ©Ÿèƒ½ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ– â˜…v3.0 NEWâ˜…
        self.currency_service = CurrencyConversionService()      # å¤–è²¨æ›ç®—ã‚µãƒ¼ãƒ“ã‚¹
        self.approval_service = ApprovalControlService()         # æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹  
        self.freee_service = FreeeIntegrationService()           # freeeé€£æºã‚µãƒ¼ãƒ“ã‚¹
        
        # å‡¦ç†å±¥æ­´ç®¡ç†
        self.progress_history = []
        logger.info("UnifiedWorkflowEngine initialized with 40-column features.")

    def _notify_progress(self, status: WorkflowStatus, step: str, 
                        progress_percent: int, message: str, 
                        details: Optional[Dict[str, Any]] = None):
        """çµ±ä¸€é€²æ—é€šçŸ¥"""
        progress = WorkflowProgress(
            status=status,
            step=step,
            progress_percent=progress_percent,
            message=message,
            timestamp=datetime.now(),
            details=details
        )
        
        self.progress_history.append(progress)
        logger.info(f"çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€²æ—: {step} - {message} ({progress_percent}%)")
        
        if self.progress_callback:
            self.progress_callback(progress)
    
    def process_single_file(self, 
                           pdf_file_data: bytes, 
                           filename: str, 
                           user_id: str,
                           mode: str = "upload") -> WorkflowResult:
        """
        å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆçµ±ä¸€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰
        
        Args:
            pdf_file_data: PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆ"upload", "test", "batch"ï¼‰
            
        Returns:
            WorkflowResult: çµ±ä¸€å‡¦ç†çµæœ
        """
        start_time = datetime.now()
        session_id = str(uuid.uuid4())
        
        try:
            logger.info(f"ğŸš€ çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹: {filename} (ãƒ¢ãƒ¼ãƒ‰: {mode})")
            
            # Step 1: çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
            file_info = self._unified_file_upload(pdf_file_data, filename)
            
            # Step 2: çµ±ä¸€AIæƒ…å ±æŠ½å‡ºå‡¦ç†
            extracted_data = self._unified_ai_extraction(pdf_file_data, filename)
            
            # Step 2.5: çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æ­£è¦åŒ–å‡¦ç†
            validated_data = self._unified_data_validation(extracted_data, filename)
            
            # ğŸ†• Step 2.6: å¤–è²¨æ›ç®—å‡¦ç† â˜…v3.0 NEWâ˜…
            currency_data = self._unified_currency_conversion(validated_data, filename)
            
            # ğŸ†• Step 2.7: æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å‡¦ç† â˜…v3.0 NEWâ˜…
            approval_data = self._unified_approval_workflow(currency_data, filename)
            
            # ğŸ†• Step 2.8: freeeé€£æºæº–å‚™ â˜…v3.0 NEWâ˜…
            integration_data = self._unified_freee_preparation(approval_data, filename)
            
            # Step 3: çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å‡¦ç†ï¼ˆ40ã‚«ãƒ©ãƒ å®Œå…¨å¯¾å¿œï¼‰
            invoice_id = self._unified_database_save(
                file_info, integration_data, filename, user_id, mode
            )
            
            # Step 4: å®Œäº†å‡¦ç†
            processing_time = (datetime.now() - start_time).total_seconds()
            
            self._notify_progress(
                WorkflowStatus.COMPLETED,
                "å‡¦ç†å®Œäº†",
                100,
                f"çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº† (ID: {invoice_id})",
                details={
                    "session_id": session_id,
                    "invoice_id": invoice_id,
                    "processing_time": processing_time,
                    "mode": mode
                }
            )
            
            logger.info(f"âœ… çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†: {filename} -> ID={invoice_id}, æ™‚é–“={processing_time:.2f}ç§’")
            
            return WorkflowResult(
                success=True,
                invoice_id=invoice_id,
                extracted_data=validated_data,
                file_info=file_info,
                processing_time=processing_time,
                progress_history=self.progress_history.copy()
            )
            
        except Exception as e:
            error_message = str(e)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            logger.error(f"âŒ çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼: {error_message}")
            
            self._notify_progress(
                WorkflowStatus.FAILED,
                "ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ",
                0,
                f"å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_message}",
                details={"error": error_message, "session_id": session_id}
            )
            
            return WorkflowResult(
                success=False,
                error_message=error_message,
                processing_time=processing_time,
                progress_history=self.progress_history.copy()
            )
    
    def _unified_file_upload(self, pdf_file_data: bytes, filename: str) -> Dict[str, Any]:
        """çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†"""
        self._notify_progress(
            WorkflowStatus.UPLOADING, 
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
            10, 
            "Google Driveã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."
        )
        
        try:
            logger.info(f"ğŸ“¤ çµ±ä¸€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {filename} ({len(pdf_file_data)} bytes)")
            
            # Google Drive APIã®å‘¼ã³å‡ºã—ï¼ˆå®Œå…¨åŒæœŸå‡¦ç†ï¼‰
            logger.info("ğŸŒ Google Drive APIã‚µãƒ¼ãƒ“ã‚¹å–å¾—ä¸­...")
            
            if not self.storage_service:
                raise Exception("Google Drive APIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
            logger.info("ğŸŒ Google Drive APIã‚µãƒ¼ãƒ“ã‚¹ç¢ºèªå®Œäº†")
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¶å¾¡ä»˜ãï¼‰
            logger.info("ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œé–‹å§‹...")
            
            file_info = self.storage_service.upload_file(
                file_content=pdf_file_data,
                filename=filename,
                folder_id=None,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ«ãƒ€
                mime_type="application/pdf"
            )
            
            logger.info(f"ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œå®Œäº†: {file_info}")
            
            if not file_info:
                raise Exception("Google Drive APIã‹ã‚‰ã®æˆ»ã‚Šå€¤ãŒNoneã§ã™")
            
            if not file_info.get('file_id'):
                raise Exception(f"ãƒ•ã‚¡ã‚¤ãƒ«IDãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {file_info}")
            
            # æˆåŠŸæ™‚ã®è©³ç´°ãƒ­ã‚°
            file_id = file_info.get('file_id')
            file_url = file_info.get('file_url', '')
            
            logger.info(f"âœ… çµ±ä¸€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {filename}")
            logger.info(f"ğŸ“Š ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœ: ID={file_id}, URL={file_url}")
            
            self._notify_progress(
                WorkflowStatus.UPLOADING,
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                30,
                f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {filename}"
            )
            
            return file_info
            
        except Exception as e:
            error_msg = f"çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            logger.exception("çµ±ä¸€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è©³ç´°ã‚¨ãƒ©ãƒ¼:")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®é€²æ—é€šçŸ¥
            self._notify_progress(
                WorkflowStatus.FAILED,
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼",
                10,
                f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)}",
                details={
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "filename": filename,
                    "file_size": len(pdf_file_data)
                }
            )
            
            raise Exception(error_msg)
    
    def _unified_ai_extraction(self, pdf_file_data: bytes, filename: str) -> Dict[str, Any]:
        """çµ±ä¸€AIæƒ…å ±æŠ½å‡ºå‡¦ç†"""
        self._notify_progress(
            WorkflowStatus.PROCESSING,
            "AIæƒ…å ±æŠ½å‡º", 
            40,
            "Gemini APIã§è«‹æ±‚æ›¸æƒ…å ±ã‚’æŠ½å‡ºä¸­..."
        )
        
        try:
            logger.info(f"ğŸ¤– çµ±ä¸€AIæŠ½å‡ºé–‹å§‹: {filename}")
            
            # çµ±ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            prompt_key = self.prompt_selector.get_recommended_prompt("upload")
            system_prompt, user_prompt = self.prompt_manager.format_prompt_for_gemini(
                prompt_key, {"invoice_image": filename}
            )
            
            # AIå‡¦ç†å®Ÿè¡Œ
            combined_prompt = f"{system_prompt}\n\n{user_prompt}"
            extracted_data = self.ai_service.analyze_pdf_content(
                pdf_file_data,
                combined_prompt
            )
            
            if not extracted_data:
                raise Exception("AIæƒ…å ±æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            logger.info(f"ğŸ¤– çµ±ä¸€AIæŠ½å‡ºå®Œäº†: {list(extracted_data.keys())}")
            
            self._notify_progress(
                WorkflowStatus.PROCESSING,
                "AIæƒ…å ±æŠ½å‡º",
                70,
                "æƒ…å ±æŠ½å‡ºå®Œäº†",
                details={"extracted_keys": list(extracted_data.keys())}
            )
            
            return extracted_data
            
        except Exception as e:
            logger.error(f"âŒ çµ±ä¸€AIæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"çµ±ä¸€AIæƒ…å ±æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def _unified_data_validation(self, extracted_data: Dict[str, Any], filename: str) -> Dict[str, Any]:
        """çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æ­£è¦åŒ–å‡¦ç†"""
        self._notify_progress(
            WorkflowStatus.PROCESSING,
            "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼",
            75,
            "AIæŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ãƒ»æ­£è¦åŒ–ã‚’å®Ÿè¡Œä¸­..."
        )
        
        try:
            logger.info(f"ğŸ” çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼é–‹å§‹: {filename}")
            
            # InvoiceValidatorã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æ­£è¦åŒ–
            logger.info("ğŸ“‹ InvoiceValidatorã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹...")
            from core.services.invoice_validator import InvoiceValidator
            logger.info("ğŸ“‹ InvoiceValidatoråˆæœŸåŒ–é–‹å§‹...")
            validator = InvoiceValidator()
            logger.info("âœ… InvoiceValidatoråˆæœŸåŒ–å®Œäº†")
            
            # æ­£è¦åŒ–å‰ã®çŠ¶æ…‹ã‚’è¨˜éŒ²
            original_currency = extracted_data.get('currency')
            logger.info(f"ğŸ” ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å‰é€šè²¨: {original_currency}")
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆextracted_dataãŒå‚ç…§æ¸¡ã—ã§æ­£è¦åŒ–ã•ã‚Œã‚‹ï¼‰
            logger.info("ğŸ” ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œé–‹å§‹...")
            validation_result = validator.validate_invoice_data(extracted_data)
            logger.info("âœ… ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå®Œäº†")
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¾Œã®çŠ¶æ…‹ã‚’ç¢ºèª
            final_currency = extracted_data.get('currency')
            logger.info(f"ğŸ” ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¾Œé€šè²¨: {final_currency}")
            
            # é€šè²¨æ­£è¦åŒ–ã®ç¢ºèªï¼ˆä¿®æ­£ç‰ˆï¼‰
            if original_currency != final_currency:
                logger.info(f"ğŸ’± é€šè²¨æ­£è¦åŒ–: {original_currency} â†’ {final_currency}")
            else:
                logger.info(f"ğŸ’± é€šè²¨ç¢ºèª: {final_currency} (å¤‰æ›´ãªã—)")
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’ãƒ­ã‚°å‡ºåŠ›
            is_valid = validation_result.get('is_valid', False)
            warnings = validation_result.get('warnings', [])
            errors = validation_result.get('errors', [])
            
            logger.info(f"ğŸ” ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å®Œäº†: valid={is_valid}, warnings={len(warnings)}, errors={len(errors)}")
            
            # è­¦å‘Šãƒ»ã‚¨ãƒ©ãƒ¼ã®ç°¡æ˜“ãƒ­ã‚°å‡ºåŠ›
            if warnings:
                logger.warning(f"âš ï¸ æ¤œè¨¼è­¦å‘Š({len(warnings)}ä»¶): {warnings[:2]}")  # æœ€åˆã®2ä»¶ã®ã¿
            if errors:
                logger.error(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼({len(errors)}ä»¶): {errors[:2]}")  # æœ€åˆã®2ä»¶ã®ã¿
            
            self._notify_progress(
                WorkflowStatus.PROCESSING,
                "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼",
                77,
                "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æ­£è¦åŒ–å®Œäº†",
                details={
                    "is_valid": is_valid,
                    "warnings_count": len(warnings),
                    "errors_count": len(errors),
                    "currency_normalized": original_currency != final_currency
                }
            )
            
            logger.info("âœ… çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å®Œäº†ã€æ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™")
            
            # é‡è¦ï¼šextracted_dataãŒæ—¢ã«æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã®ã¾ã¾è¿”ã™
            return extracted_data  # validated_data = extracted_data.copy() ã§ã¯ãªãç›´æ¥è¿”ã™
            
        except Exception as e:
            logger.error(f"âŒ çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            logger.exception("è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±:")  # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å‡ºåŠ›
            # æ¤œè¨¼ã«å¤±æ•—ã—ã¦ã‚‚å‡¦ç†ã‚’ç¶™ç¶šï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ï¼‰
            logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å¤±æ•—ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã§å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™")
            return extracted_data
    
    def _unified_database_save(self, 
                              file_info: Dict[str, Any], 
                              extracted_data: Dict[str, Any], 
                              filename: str, 
                              user_id: str,
                              mode: str) -> str:
        """çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å‡¦ç†"""
        self._notify_progress(
            WorkflowStatus.SAVING,
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜",
            80,
            "è«‹æ±‚æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ä¸­..."
        )
        
        try:
            logger.info(f"ğŸ’¾ çµ±ä¸€DBä¿å­˜é–‹å§‹: {filename} (ãƒ¢ãƒ¼ãƒ‰: {mode})")
            
            # çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æº–å‚™
            invoice_record = {
                # ğŸ”‘ RLSå¯¾å¿œ: user_emailã‚’æ˜ç¤ºçš„ã«è¨­å®š â˜…RLS FIXâ˜…
                "user_email": user_id,  # user_idã¯èªè¨¼æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
                "created_by": user_id,  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ä¿æŒ
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿æƒ…å ±
                "file_id": file_info.get("file_id", ""),  # file_pathã‹ã‚‰file_idã«ä¿®æ­£
                "file_name": filename,
                "extracted_data": extracted_data,
                "status": "extracted",
                "processing_mode": mode,
                
                # æŠ½å‡ºæ¸ˆã¿åŸºæœ¬æƒ…å ±
                "issuer_name": extracted_data.get("issuer"),
                "total_amount_tax_included": extracted_data.get("amount_inclusive_tax"),
                "issue_date": extracted_data.get("issue_date"),
                "main_invoice_number": extracted_data.get("main_invoice_number")  # çµ±ä¸€åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¾©æ´»
            }
            
            # ğŸ” RLSãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ  â˜…DEBUGâ˜…
            logger.info(f"ğŸ” RLS Debug - user_emailè¨­å®š: {user_id}")
            logger.info(f"ğŸ” RLS Debug - invoice_record keys: {list(invoice_record.keys())}")
            logger.info(f"ğŸ” RLS Debug - file_name: {filename}")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            save_result = self.database_service.insert_invoice(invoice_record)
            
            if not save_result:
                raise Exception("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            invoice_id = save_result.get('id')
            logger.info(f"ğŸ’¾ çµ±ä¸€DBä¿å­˜å®Œäº†: ID={invoice_id}")
            
            self._notify_progress(
                WorkflowStatus.SAVING,
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜",
                90,
                f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº† (ID: {invoice_id})"
            )
            
            return str(invoice_id)
            
        except Exception as e:
            logger.error(f"âŒ çµ±ä¸€DBä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def process_uploaded_files(self, 
                             uploaded_files, 
                             user_id: str,
                             mode: str = "upload") -> Dict[str, Any]:
        """
        Streamlit uploaded files ã®ç›´æ¥å‡¦ç†ï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰
        
        Args:
            uploaded_files: Streamlit st.file_uploader ã‹ã‚‰è¿”ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            
        Returns:
            ãƒãƒƒãƒå‡¦ç†çµæœè¾æ›¸
        """
        logger.info(f"ğŸ“¤ Streamlitã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {len(uploaded_files)}ä»¶")
        
        try:
            # Streamlit uploaded files ã‚’ files_data å½¢å¼ã«å¤‰æ›
            files_data = []
            for uploaded_file in uploaded_files:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Š
                pdf_data = uploaded_file.read()
                files_data.append({
                    'filename': uploaded_file.name,
                    'data': pdf_data
                })
                logger.info(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›å®Œäº†: {uploaded_file.name} ({len(pdf_data):,} bytes)")
            
            # æ—¢å­˜ã®ãƒãƒƒãƒå‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
            result = self.process_batch_files(files_data, user_id, mode)
            
            logger.info(f"âœ… Streamlitã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†: {len(uploaded_files)}ä»¶")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Streamlitã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def process_batch_files(self, 
                           files_data: List[Dict[str, Any]], 
                           user_id: str,
                           mode: str = "batch") -> Dict[str, Any]:
        """
        ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆçµ±ä¸€å®Ÿè£…ï¼‰
        
        Args:
            files_data: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ [{'filename': str, 'data': bytes}]
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            
        Returns:
            ãƒãƒƒãƒå‡¦ç†çµæœè¾æ›¸
        """
        start_time = datetime.now()
        session_id = str(uuid.uuid4())
        
        logger.info(f"ğŸ”„ çµ±ä¸€ãƒãƒƒãƒå‡¦ç†é–‹å§‹: {len(files_data)}ä»¶ (ãƒ¢ãƒ¼ãƒ‰: {mode})")
        
        results = []
        successful_files = 0
        
        for i, file_info in enumerate(files_data, 1):
            try:
                self._notify_progress(
                    WorkflowStatus.PROCESSING,
                    "ãƒãƒƒãƒå‡¦ç†",
                    int((i / len(files_data)) * 80),  # 80%ã¾ã§ä½¿ç”¨
                    f"å‡¦ç†ä¸­: {file_info['filename']} ({i}/{len(files_data)})"
                )
                
                # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’çµ±ä¸€ã‚¨ãƒ³ã‚¸ãƒ³ã§å®Ÿè¡Œ
                result = self.process_single_file(
                    file_info['data'],
                    file_info['filename'],
                    user_id,
                    mode
                )
                
                if result.success:
                    successful_files += 1
                
                results.append({
                    'filename': file_info['filename'],
                    'success': result.success,
                    'invoice_id': result.invoice_id,
                    'extracted_data': result.extracted_data,
                    'error_message': result.error_message,
                    'processing_time': result.processing_time
                })
                
            except Exception as e:
                logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {file_info['filename']} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                results.append({
                    'filename': file_info['filename'],
                    'success': False,
                    'error_message': str(e),
                    'processing_time': 0
                })
        
        # ãƒãƒƒãƒçµæœé›†è¨ˆ
        total_files = len(files_data)
        failed_files = total_files - successful_files
        total_processing_time = (datetime.now() - start_time).total_seconds()
        
        self._notify_progress(
            WorkflowStatus.COMPLETED,
            "ãƒãƒƒãƒå‡¦ç†å®Œäº†",
            100,
            f"ãƒãƒƒãƒå‡¦ç†å®Œäº†: æˆåŠŸ={successful_files}ä»¶, å¤±æ•—={failed_files}ä»¶"
        )
        
        logger.info(f"âœ… çµ±ä¸€ãƒãƒƒãƒå‡¦ç†å®Œäº†: æˆåŠŸ={successful_files}/{total_files}ä»¶, æ™‚é–“={total_processing_time:.2f}ç§’")
        
        return {
            'session_id': session_id,
            'total_files': total_files,
            'successful_files': successful_files,
            'failed_files': failed_files,
            'results': results,
            'total_processing_time': total_processing_time,
            'mode': mode
        }
    
    def get_progress_history(self) -> List[WorkflowProgress]:
        """é€²æ—å±¥æ­´å–å¾—"""
        return self.progress_history.copy()
    
    def reset_progress(self):
        """é€²æ—å±¥æ­´ãƒªã‚»ãƒƒãƒˆ"""
        self.progress_history.clear() 

    def process_ocr_test_from_drive(self, folder_id: str, user_id: str, max_files: int = -1) -> Dict[str, Any]:
        """
        Google Driveã®æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦OCRãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹

        Args:
            folder_id (str): Google Driveã®ãƒ•ã‚©ãƒ«ãƒ€ID
            user_id (str): å®Ÿè¡Œãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            max_files (int, optional): å‡¦ç†ã™ã‚‹æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«æ•°. Defaults to -1 (ã™ã¹ã¦).

        Returns:
            Dict[str, Any]: process_batch_files ã¨åŒã˜å½¢å¼ã®ãƒãƒƒãƒå‡¦ç†çµæœ
        """
        self._notify_progress(WorkflowStatus.PROCESSING, "OCR_TEST_PREPARATION", 5, f"Google Driveãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—é–‹å§‹: {folder_id}")

        try:
            # 1. Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
            if not self.storage_service:
                raise ValueError("Storage service (Google Drive) is not configured.")
            
            from utils.ocr_test_helper import OCRTestManager
            ocr_manager = OCRTestManager(self.storage_service, None, None)
            pdf_files = ocr_manager.get_drive_pdfs(folder_id)

            if not pdf_files:
                logger.warning(f"æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {folder_id}")
                return {"error": f"No PDF files found in folder {folder_id}", "results": [], "total_files": 0, "successful_files": 0, "failed_files": 0}

            # 2. ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™
            if max_files != -1 and len(pdf_files) > max_files:
                pdf_files = pdf_files[:max_files]
            
            self._notify_progress(WorkflowStatus.PROCESSING, "OCR_TEST_PREPARATION", 10, f"{len(pdf_files)}ä»¶ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™")

            # 3. ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
            files_data = []
            for i, file_info in enumerate(pdf_files):
                try:
                    progress = 10 + int((i / len(pdf_files)) * 20) # 10%-30%
                    self._notify_progress(WorkflowStatus.PROCESSING, "FILE_DOWNLOAD", progress, f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ ({i+1}/{len(pdf_files)}): {file_info['name']}")
                    
                    file_data = self.storage_service.download_file(file_info['id'])
                    if file_data:
                        files_data.append({
                            'filename': file_info['name'],
                            'data': file_data
                        })
                    else:
                        logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒç©ºï¼‰: {file_info['name']}")

                except Exception as e:
                    logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ï¼‰: {file_info['name']} - {e}", exc_info=True)
            
            if not files_data:
                logger.error("å‡¦ç†å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«ã™ã¹ã¦å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return {"error": "Failed to download any processable files.", "results": [], "total_files": len(pdf_files), "successful_files": 0, "failed_files": len(pdf_files)}

            # 4. æ—¢å­˜ã®ãƒãƒƒãƒå‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
            self._notify_progress(WorkflowStatus.PROCESSING, "BATCH_PROCESSING_START", 30, "AIã«ã‚ˆã‚‹ä¸€æ‹¬è§£æå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
            return self.process_batch_files(
                files_data=files_data,
                user_id=user_id,
                mode="ocr_test"
            )

        except Exception as e:
            logger.error(f"OCRãƒ†ã‚¹ãƒˆæº–å‚™ãƒ•ã‚§ãƒ¼ã‚ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
            self._notify_progress(WorkflowStatus.FAILED, "OCR_TEST_PREPARATION", 0, f"OCRãƒ†ã‚¹ãƒˆæº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": f"An error occurred during OCR test preparation: {e}"} 
    
    # ============================================================
    # ğŸ†• 40ã‚«ãƒ©ãƒ æ–°æ©Ÿèƒ½å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ â˜…v3.0 NEWâ˜…
    # ============================================================
    
    def _unified_currency_conversion(self, validated_data: Dict[str, Any], filename: str) -> Dict[str, Any]:
        """çµ±ä¸€å¤–è²¨æ›ç®—å‡¦ç†ï¼ˆ40ã‚«ãƒ©ãƒ æ–°æ©Ÿèƒ½ï¼‰
        
        Args:
            validated_data: æ¤œè¨¼æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            Dict: å¤–è²¨æ›ç®—ãƒ‡ãƒ¼ã‚¿è¿½åŠ æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        try:
            self._notify_progress(
                WorkflowStatus.PROCESSING,
                "å¤–è²¨æ›ç®—å‡¦ç†",
                75,
                "å¤–è²¨æ›ç®—å‡¦ç†ä¸­..."
            )
            
            logger.info(f"ğŸ’± å¤–è²¨æ›ç®—å‡¦ç†é–‹å§‹: {filename}")
            
            # é€šè²¨æƒ…å ±å–å¾—
            currency = validated_data.get('currency', 'JPY')
            amount = validated_data.get('amount_inclusive_tax', 0)
            
            # JPYã®å ´åˆã¯æ›ç®—ä¸è¦
            if currency.upper() == 'JPY':
                logger.info(f"ğŸ’± JPYè«‹æ±‚æ›¸ã®ãŸã‚æ›ç®—ä¸è¦: {filename}")
                validated_data.update({
                    'exchange_rate': 1.0,
                    'jpy_amount': amount,
                    'currency_conversion_status': 'no_conversion_needed'
                })
                return validated_data
            
            # å¤–è²¨æ›ç®—å®Ÿè¡Œ
            if amount and amount > 0:
                conversion_result = self.currency_service.convert_to_jpy(amount, currency)
                
                validated_data.update({
                    'exchange_rate': conversion_result['exchange_rate'],
                    'jpy_amount': conversion_result['jpy_amount'],
                    'currency_conversion_status': 'converted',
                    'conversion_timestamp': conversion_result['conversion_timestamp'],
                    'rate_source': conversion_result['source']
                })
                
                logger.info(f"âœ… å¤–è²¨æ›ç®—å®Œäº†: {amount} {currency} â†’ Â¥{conversion_result['jpy_amount']:,.2f}")
            else:
                logger.warning(f"âš ï¸ é‡‘é¡ä¸æ˜ã®ãŸã‚å¤–è²¨æ›ç®—ã‚¹ã‚­ãƒƒãƒ—: {filename}")
                validated_data.update({
                    'currency_conversion_status': 'skipped_no_amount'
                })
            
            return validated_data
            
        except Exception as e:
            logger.error(f"âŒ å¤–è²¨æ›ç®—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã§ã‚‚å‡¦ç†ã‚’ç¶™ç¶šï¼ˆæ›ç®—ãªã—ã§ï¼‰
            validated_data.update({
                'currency_conversion_status': 'error',
                'currency_conversion_error': str(e)
            })
            return validated_data
    
    def _unified_approval_workflow(self, currency_data: Dict[str, Any], filename: str) -> Dict[str, Any]:
        """çµ±ä¸€æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å‡¦ç†ï¼ˆ40ã‚«ãƒ©ãƒ æ–°æ©Ÿèƒ½ï¼‰
        
        Args:
            currency_data: å¤–è²¨æ›ç®—æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            Dict: æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‡ãƒ¼ã‚¿è¿½åŠ æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        try:
            self._notify_progress(
                WorkflowStatus.PROCESSING,
                "æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å‡¦ç†",
                80,
                "æ‰¿èªè¦å¦åˆ¤å®šä¸­..."
            )
            
            logger.info(f"âœ… æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å‡¦ç†é–‹å§‹: {filename}")
            
            # æ‰¿èªè¦å¦è©•ä¾¡
            approval_evaluation = self.approval_service.evaluate_approval_requirement(currency_data)
            
            if approval_evaluation['requires_approval']:
                # æ‰¿èªå¿…è¦ãªå ´åˆ
                approval_level = approval_evaluation['approval_level']
                approver_email = self.approval_service.assign_approver(approval_level)
                
                currency_data.update({
                    'approval_status': 'pending',
                    'approval_level': approval_level,
                    'current_approver': approver_email,
                    'approval_reason': approval_evaluation['reason'],
                    'approval_evaluation': approval_evaluation
                })
                
                logger.info(f"ğŸ“‹ æ‰¿èªå¿…è¦: ãƒ¬ãƒ™ãƒ«={approval_level}, æ‰¿èªè€…={approver_email}")
                
                # æ‰¿èªé€šçŸ¥é€ä¿¡ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯æ‰¿èªè€…æƒ…å ±ã‚’å–å¾—ï¼‰
                # self.approval_service.send_approval_notification(...)
                
            else:
                # è‡ªå‹•æ‰¿èªå¯èƒ½ãªå ´åˆ
                currency_data.update({
                    'approval_status': 'auto_approved',
                    'approved_by': 'system',
                    'approved_at': datetime.now().isoformat(),
                    'approval_reason': 'è‡ªå‹•æ‰¿èªåŸºæº–ã‚’æº€ãŸã™'
                })
                
                logger.info(f"ğŸŸ¢ è‡ªå‹•æ‰¿èª: {filename}")
            
            return currency_data
            
        except Exception as e:
            logger.error(f"âŒ æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯pendingã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ä¿å­˜
            currency_data.update({
                'approval_status': 'pending',
                'approval_error': str(e)
            })
            return currency_data
    
    def _unified_freee_preparation(self, approval_data: Dict[str, Any], filename: str) -> Dict[str, Any]:
        """çµ±ä¸€freeeé€£æºæº–å‚™å‡¦ç†ï¼ˆ40ã‚«ãƒ©ãƒ æ–°æ©Ÿèƒ½ï¼‰
        
        Args:
            approval_data: æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            Dict: freeeé€£æºæº–å‚™æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        try:
            self._notify_progress(
                WorkflowStatus.PROCESSING,
                "freeeé€£æºæº–å‚™",
                85,
                "freeeé€£æºãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­..."
            )
            
            logger.info(f"ğŸ“Š freeeé€£æºæº–å‚™é–‹å§‹: {filename}")
            
            # æ‰¿èªæ¸ˆã¿ã®å ´åˆã®ã¿freeeé€£æºæº–å‚™
            approval_status = approval_data.get('approval_status', 'pending')
            
            if approval_status in ['approved', 'auto_approved']:
                # æ‰¿èªæ¸ˆã¿ï¼šfreeeé€£æºæº–å‚™å®Ÿè¡Œ
                try:
                    # freeeé€£æºãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå®Ÿéš›ã®é€£æºã¯åˆ¥é€”å®Ÿè¡Œï¼‰
                    category = self._detect_expense_category(approval_data)
                    account_mapping = self.freee_service.map_expense_category(category)
                    batch_id = self.freee_service.generate_batch_id()
                    
                    approval_data.update({
                        'freee_ready': True,
                        'freee_batch_id': batch_id,
                        'freee_account_mapping': account_mapping,
                        'freee_category': category,
                        'exported_to_freee': False,  # å®Ÿéš›ã®é€£æºã¯ã¾ã 
                        'freee_preparation_status': 'ready'
                    })
                    
                    logger.info(f"âœ… freeeé€£æºæº–å‚™å®Œäº†: ãƒãƒƒãƒID={batch_id}, å‹˜å®šç§‘ç›®={account_mapping['name']}")
                    
                except Exception as freee_error:
                    logger.warning(f"âš ï¸ freeeé€£æºæº–å‚™ã§ã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰: {freee_error}")
                    approval_data.update({
                        'freee_ready': False,
                        'freee_preparation_status': 'error',
                        'freee_preparation_error': str(freee_error)
                    })
            else:
                # æœªæ‰¿èªï¼šfreeeé€£æºã¯ä¿ç•™
                approval_data.update({
                    'freee_ready': False,
                    'freee_preparation_status': 'pending_approval',
                    'exported_to_freee': False
                })
                
                logger.info(f"ğŸ“‹ æœªæ‰¿èªã®ãŸã‚freeeé€£æºã¯ä¿ç•™: {filename}")
            
            return approval_data
            
        except Exception as e:
            logger.error(f"âŒ freeeé€£æºæº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã§ã‚‚å‡¦ç†ã‚’ç¶™ç¶š
            approval_data.update({
                'freee_ready': False,
                'freee_preparation_status': 'error',
                'freee_preparation_error': str(e)
            })
            return approval_data
    
    def _detect_expense_category(self, invoice_data: Dict[str, Any]) -> str:
        """çµŒè²»ã‚«ãƒ†ã‚´ãƒªæ¨å®šï¼ˆå†…éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼‰
        
        Args:
            invoice_data: è«‹æ±‚æ›¸ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            str: æ¨å®šã‚«ãƒ†ã‚´ãƒª
        """
        # FreeeIntegrationService ã® _detect_expense_category ã‚’æ´»ç”¨
        return self.freee_service._detect_expense_category(invoice_data) 