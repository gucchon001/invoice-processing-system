"""
çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³

å…¨ã¦ã®è«‹æ±‚æ›¸å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’çµ±ä¸€ç®¡ç†ã™ã‚‹ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹
é‡è¤‡ã‚³ãƒ¼ãƒ‰ã®çµ±åˆã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§ã®å‘ä¸Šã‚’ç›®çš„ã¨ã™ã‚‹
"""

import logging
import time
from datetime import datetime
from typing import Dict, Any, Optional, Callable, List
import uuid

from core.models.workflow_models import WorkflowStatus, WorkflowProgress, WorkflowResult
from core.services.unified_prompt_manager import UnifiedPromptManager, PromptSelector
from infrastructure.ai.gemini_helper import GeminiAPIManager
from infrastructure.storage.google_drive_helper import GoogleDriveManager
from infrastructure.database.database import DatabaseManager
from utils.log_config import get_logger

logger = get_logger(__name__)

class UnifiedWorkflowEngine:
    """çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, 
                 ai_service: GeminiAPIManager,
                 storage_service: GoogleDriveManager,
                 database_service: DatabaseManager,
                 progress_callback: Optional[Callable[[WorkflowProgress], None]] = None):
        """
        Args:
            ai_service: AIæƒ…å ±æŠ½å‡ºã‚µãƒ¼ãƒ“ã‚¹
            storage_service: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µãƒ¼ãƒ“ã‚¹
            database_service: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µãƒ¼ãƒ“ã‚¹
            progress_callback: é€²æ—é€šçŸ¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        """
        self.ai_service = ai_service
        self.storage_service = storage_service
        self.database_service = database_service
        self.progress_callback = progress_callback
        
        # çµ±ä¸€ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        self.prompt_manager = UnifiedPromptManager()
        self.prompt_selector = PromptSelector(self.prompt_manager)
        
        # å‡¦ç†å±¥æ­´ç®¡ç†
        self.progress_history = []
        logger.info("UnifiedWorkflowEngine initialized.")

    def _notify_progress(self, status: WorkflowStatus, step: str, 
                        progress_percent: int, message: str, 
                        details: Optional[Dict[str, Any]] = None):
        """çµ±ä¸€é€²æ—é€šçŸ¥"""
        progress = WorkflowProgress(
            status=status,
            step=step,
            progress_percent=progress_percent,
            message=message,
            timestamp=datetime.now(),
            details=details
        )
        
        self.progress_history.append(progress)
        logger.info(f"çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€²æ—: {step} - {message} ({progress_percent}%)")
        
        if self.progress_callback:
            self.progress_callback(progress)
    
    def process_single_file(self, 
                           pdf_file_data: bytes, 
                           filename: str, 
                           user_id: str,
                           mode: str = "upload") -> WorkflowResult:
        """
        å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆçµ±ä¸€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰
        
        Args:
            pdf_file_data: PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆ"upload", "test", "batch"ï¼‰
            
        Returns:
            WorkflowResult: çµ±ä¸€å‡¦ç†çµæœ
        """
        start_time = datetime.now()
        session_id = str(uuid.uuid4())
        
        try:
            logger.info(f"ğŸš€ çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹: {filename} (ãƒ¢ãƒ¼ãƒ‰: {mode})")
            
            # Step 1: çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
            file_info = self._unified_file_upload(pdf_file_data, filename)
            
            # Step 2: çµ±ä¸€AIæƒ…å ±æŠ½å‡ºå‡¦ç†
            extracted_data = self._unified_ai_extraction(pdf_file_data, filename)
            
            # Step 2.5: çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æ­£è¦åŒ–å‡¦ç†
            validated_data = self._unified_data_validation(extracted_data, filename)
            
            # Step 3: çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å‡¦ç†
            invoice_id = self._unified_database_save(
                file_info, validated_data, filename, user_id, mode
            )
            
            # Step 4: å®Œäº†å‡¦ç†
            processing_time = (datetime.now() - start_time).total_seconds()
            
            self._notify_progress(
                WorkflowStatus.COMPLETED,
                "å‡¦ç†å®Œäº†",
                100,
                f"çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº† (ID: {invoice_id})",
                details={
                    "session_id": session_id,
                    "invoice_id": invoice_id,
                    "processing_time": processing_time,
                    "mode": mode
                }
            )
            
            logger.info(f"âœ… çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†: {filename} -> ID={invoice_id}, æ™‚é–“={processing_time:.2f}ç§’")
            
            return WorkflowResult(
                success=True,
                invoice_id=invoice_id,
                extracted_data=validated_data,
                file_info=file_info,
                processing_time=processing_time,
                progress_history=self.progress_history.copy()
            )
            
        except Exception as e:
            error_message = str(e)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            logger.error(f"âŒ çµ±ä¸€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼: {error_message}")
            
            self._notify_progress(
                WorkflowStatus.FAILED,
                "ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ",
                0,
                f"å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_message}",
                details={"error": error_message, "session_id": session_id}
            )
            
            return WorkflowResult(
                success=False,
                error_message=error_message,
                processing_time=processing_time,
                progress_history=self.progress_history.copy()
            )
    
    def _unified_file_upload(self, pdf_file_data: bytes, filename: str) -> Dict[str, Any]:
        """çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†"""
        self._notify_progress(
            WorkflowStatus.UPLOADING, 
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
            10, 
            "Google Driveã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."
        )
        
        try:
            logger.info(f"ğŸ“¤ çµ±ä¸€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {filename} ({len(pdf_file_data)} bytes)")
            
            # Google Drive APIã®å‘¼ã³å‡ºã—ï¼ˆå®Œå…¨åŒæœŸå‡¦ç†ï¼‰
            logger.info("ğŸŒ Google Drive APIã‚µãƒ¼ãƒ“ã‚¹å–å¾—ä¸­...")
            
            if not self.storage_service:
                raise Exception("Google Drive APIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
            logger.info("ğŸŒ Google Drive APIã‚µãƒ¼ãƒ“ã‚¹ç¢ºèªå®Œäº†")
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¶å¾¡ä»˜ãï¼‰
            logger.info("ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œé–‹å§‹...")
            
            file_info = self.storage_service.upload_file(
                file_content=pdf_file_data,
                filename=filename,
                folder_id=None,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ«ãƒ€
                mime_type="application/pdf"
            )
            
            logger.info(f"ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œå®Œäº†: {file_info}")
            
            if not file_info:
                raise Exception("Google Drive APIã‹ã‚‰ã®æˆ»ã‚Šå€¤ãŒNoneã§ã™")
            
            if not file_info.get('file_id'):
                raise Exception(f"ãƒ•ã‚¡ã‚¤ãƒ«IDãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {file_info}")
            
            # æˆåŠŸæ™‚ã®è©³ç´°ãƒ­ã‚°
            file_id = file_info.get('file_id')
            file_url = file_info.get('file_url', '')
            
            logger.info(f"âœ… çµ±ä¸€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {filename}")
            logger.info(f"ğŸ“Š ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœ: ID={file_id}, URL={file_url}")
            
            self._notify_progress(
                WorkflowStatus.UPLOADING,
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                30,
                f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {filename}"
            )
            
            return file_info
            
        except Exception as e:
            error_msg = f"çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            logger.exception("çµ±ä¸€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è©³ç´°ã‚¨ãƒ©ãƒ¼:")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®é€²æ—é€šçŸ¥
            self._notify_progress(
                WorkflowStatus.FAILED,
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼",
                10,
                f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)}",
                details={
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "filename": filename,
                    "file_size": len(pdf_file_data)
                }
            )
            
            raise Exception(error_msg)
    
    def _unified_ai_extraction(self, pdf_file_data: bytes, filename: str) -> Dict[str, Any]:
        """çµ±ä¸€AIæƒ…å ±æŠ½å‡ºå‡¦ç†"""
        self._notify_progress(
            WorkflowStatus.PROCESSING,
            "AIæƒ…å ±æŠ½å‡º", 
            40,
            "Gemini APIã§è«‹æ±‚æ›¸æƒ…å ±ã‚’æŠ½å‡ºä¸­..."
        )
        
        try:
            logger.info(f"ğŸ¤– çµ±ä¸€AIæŠ½å‡ºé–‹å§‹: {filename}")
            
            # çµ±ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            prompt_key = self.prompt_selector.get_recommended_prompt("upload")
            system_prompt, user_prompt = self.prompt_manager.format_prompt_for_gemini(
                prompt_key, {"invoice_image": filename}
            )
            
            # AIå‡¦ç†å®Ÿè¡Œ
            combined_prompt = f"{system_prompt}\n\n{user_prompt}"
            extracted_data = self.ai_service.analyze_pdf_content(
                pdf_file_data,
                combined_prompt
            )
            
            if not extracted_data:
                raise Exception("AIæƒ…å ±æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            logger.info(f"ğŸ¤– çµ±ä¸€AIæŠ½å‡ºå®Œäº†: {list(extracted_data.keys())}")
            
            self._notify_progress(
                WorkflowStatus.PROCESSING,
                "AIæƒ…å ±æŠ½å‡º",
                70,
                "æƒ…å ±æŠ½å‡ºå®Œäº†",
                details={"extracted_keys": list(extracted_data.keys())}
            )
            
            return extracted_data
            
        except Exception as e:
            logger.error(f"âŒ çµ±ä¸€AIæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"çµ±ä¸€AIæƒ…å ±æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def _unified_data_validation(self, extracted_data: Dict[str, Any], filename: str) -> Dict[str, Any]:
        """çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æ­£è¦åŒ–å‡¦ç†"""
        self._notify_progress(
            WorkflowStatus.PROCESSING,
            "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼",
            75,
            "AIæŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ãƒ»æ­£è¦åŒ–ã‚’å®Ÿè¡Œä¸­..."
        )
        
        try:
            logger.info(f"ğŸ” çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼é–‹å§‹: {filename}")
            
            # InvoiceValidatorã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æ­£è¦åŒ–
            logger.info("ğŸ“‹ InvoiceValidatorã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹...")
            from core.services.invoice_validator import InvoiceValidator
            logger.info("ğŸ“‹ InvoiceValidatoråˆæœŸåŒ–é–‹å§‹...")
            validator = InvoiceValidator()
            logger.info("âœ… InvoiceValidatoråˆæœŸåŒ–å®Œäº†")
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆãƒ‡ãƒ¼ã‚¿ãŒæ­£è¦åŒ–ã•ã‚Œã‚‹ï¼‰
            logger.info("ğŸ” ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œé–‹å§‹...")
            validation_result = validator.validate_invoice_data(extracted_data)
            logger.info("âœ… ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå®Œäº†")
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆextracted_dataã¯å‚ç…§æ¸¡ã—ã§æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ï¼‰
            validated_data = extracted_data.copy()
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’ãƒ­ã‚°å‡ºåŠ›
            is_valid = validation_result.get('is_valid', False)
            warnings = validation_result.get('warnings', [])
            errors = validation_result.get('errors', [])
            
            logger.info(f"ğŸ” ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å®Œäº†: valid={is_valid}, warnings={len(warnings)}, errors={len(errors)}")
            
            # é€šè²¨æ­£è¦åŒ–ã®ç¢ºèª
            original_currency = extracted_data.get('currency')
            final_currency = validated_data.get('currency')
            if original_currency != final_currency:
                logger.info(f"ğŸ’± é€šè²¨æ­£è¦åŒ–: {original_currency} â†’ {final_currency}")
            else:
                logger.info(f"ğŸ’± é€šè²¨ç¢ºèª: {original_currency} (å¤‰æ›´ãªã—)")
            
            # è­¦å‘Šãƒ»ã‚¨ãƒ©ãƒ¼ã®ç°¡æ˜“ãƒ­ã‚°å‡ºåŠ›
            if warnings:
                logger.warning(f"âš ï¸ æ¤œè¨¼è­¦å‘Š({len(warnings)}ä»¶): {warnings[:2]}")  # æœ€åˆã®2ä»¶ã®ã¿
            if errors:
                logger.error(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼({len(errors)}ä»¶): {errors[:2]}")  # æœ€åˆã®2ä»¶ã®ã¿
            
            self._notify_progress(
                WorkflowStatus.PROCESSING,
                "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼",
                77,
                "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æ­£è¦åŒ–å®Œäº†",
                details={
                    "is_valid": is_valid,
                    "warnings_count": len(warnings),
                    "errors_count": len(errors),
                    "currency_normalized": original_currency != final_currency
                }
            )
            
            logger.info("âœ… çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å®Œäº†ã€æ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™")
            return validated_data
            
        except Exception as e:
            logger.error(f"âŒ çµ±ä¸€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            logger.exception("è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±:")  # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å‡ºåŠ›
            # æ¤œè¨¼ã«å¤±æ•—ã—ã¦ã‚‚å‡¦ç†ã‚’ç¶™ç¶šï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ï¼‰
            logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å¤±æ•—ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã§å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™")
            return extracted_data
    
    def _unified_database_save(self, 
                              file_info: Dict[str, Any], 
                              extracted_data: Dict[str, Any], 
                              filename: str, 
                              user_id: str,
                              mode: str) -> str:
        """çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å‡¦ç†"""
        self._notify_progress(
            WorkflowStatus.SAVING,
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜",
            80,
            "è«‹æ±‚æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ä¸­..."
        )
        
        try:
            logger.info(f"ğŸ’¾ çµ±ä¸€DBä¿å­˜é–‹å§‹: {filename} (ãƒ¢ãƒ¼ãƒ‰: {mode})")
            
            # çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æº–å‚™
            invoice_record = {
                "file_id": file_info.get("file_id", ""),  # file_pathã‹ã‚‰file_idã«ä¿®æ­£
                "file_name": filename,
                "extracted_data": extracted_data,
                "created_by": user_id,
                "status": "extracted",
                "processing_mode": mode,
                "issuer_name": extracted_data.get("issuer"),
                "total_amount_tax_included": extracted_data.get("amount_inclusive_tax"),
                "issue_date": extracted_data.get("issue_date"),
                "invoice_number": extracted_data.get("main_invoice_number")
            }
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            save_result = self.database_service.insert_invoice(invoice_record)
            
            if not save_result:
                raise Exception("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            invoice_id = save_result.get('id')
            logger.info(f"ğŸ’¾ çµ±ä¸€DBä¿å­˜å®Œäº†: ID={invoice_id}")
            
            self._notify_progress(
                WorkflowStatus.SAVING,
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜",
                90,
                f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº† (ID: {invoice_id})"
            )
            
            return str(invoice_id)
            
        except Exception as e:
            logger.error(f"âŒ çµ±ä¸€DBä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def process_uploaded_files(self, 
                             uploaded_files, 
                             user_id: str,
                             mode: str = "upload") -> Dict[str, Any]:
        """
        Streamlit uploaded files ã®ç›´æ¥å‡¦ç†ï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰
        
        Args:
            uploaded_files: Streamlit st.file_uploader ã‹ã‚‰è¿”ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            
        Returns:
            ãƒãƒƒãƒå‡¦ç†çµæœè¾æ›¸
        """
        logger.info(f"ğŸ“¤ Streamlitã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {len(uploaded_files)}ä»¶")
        
        try:
            # Streamlit uploaded files ã‚’ files_data å½¢å¼ã«å¤‰æ›
            files_data = []
            for uploaded_file in uploaded_files:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Š
                pdf_data = uploaded_file.read()
                files_data.append({
                    'filename': uploaded_file.name,
                    'data': pdf_data
                })
                logger.info(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›å®Œäº†: {uploaded_file.name} ({len(pdf_data):,} bytes)")
            
            # æ—¢å­˜ã®ãƒãƒƒãƒå‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
            result = self.process_batch_files(files_data, user_id, mode)
            
            logger.info(f"âœ… Streamlitã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†: {len(uploaded_files)}ä»¶")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Streamlitã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def process_batch_files(self, 
                           files_data: List[Dict[str, Any]], 
                           user_id: str,
                           mode: str = "batch") -> Dict[str, Any]:
        """
        ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆçµ±ä¸€å®Ÿè£…ï¼‰
        
        Args:
            files_data: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ [{'filename': str, 'data': bytes}]
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            
        Returns:
            ãƒãƒƒãƒå‡¦ç†çµæœè¾æ›¸
        """
        start_time = datetime.now()
        session_id = str(uuid.uuid4())
        
        logger.info(f"ğŸ”„ çµ±ä¸€ãƒãƒƒãƒå‡¦ç†é–‹å§‹: {len(files_data)}ä»¶ (ãƒ¢ãƒ¼ãƒ‰: {mode})")
        
        results = []
        successful_files = 0
        
        for i, file_info in enumerate(files_data, 1):
            try:
                self._notify_progress(
                    WorkflowStatus.PROCESSING,
                    "ãƒãƒƒãƒå‡¦ç†",
                    int((i / len(files_data)) * 80),  # 80%ã¾ã§ä½¿ç”¨
                    f"å‡¦ç†ä¸­: {file_info['filename']} ({i}/{len(files_data)})"
                )
                
                # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’çµ±ä¸€ã‚¨ãƒ³ã‚¸ãƒ³ã§å®Ÿè¡Œ
                result = self.process_single_file(
                    file_info['data'],
                    file_info['filename'],
                    user_id,
                    mode
                )
                
                if result.success:
                    successful_files += 1
                
                results.append({
                    'filename': file_info['filename'],
                    'success': result.success,
                    'invoice_id': result.invoice_id,
                    'extracted_data': result.extracted_data,
                    'error_message': result.error_message,
                    'processing_time': result.processing_time
                })
                
            except Exception as e:
                logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {file_info['filename']} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                results.append({
                    'filename': file_info['filename'],
                    'success': False,
                    'error_message': str(e),
                    'processing_time': 0
                })
        
        # ãƒãƒƒãƒçµæœé›†è¨ˆ
        total_files = len(files_data)
        failed_files = total_files - successful_files
        total_processing_time = (datetime.now() - start_time).total_seconds()
        
        self._notify_progress(
            WorkflowStatus.COMPLETED,
            "ãƒãƒƒãƒå‡¦ç†å®Œäº†",
            100,
            f"ãƒãƒƒãƒå‡¦ç†å®Œäº†: æˆåŠŸ={successful_files}ä»¶, å¤±æ•—={failed_files}ä»¶"
        )
        
        logger.info(f"âœ… çµ±ä¸€ãƒãƒƒãƒå‡¦ç†å®Œäº†: æˆåŠŸ={successful_files}/{total_files}ä»¶, æ™‚é–“={total_processing_time:.2f}ç§’")
        
        return {
            'session_id': session_id,
            'total_files': total_files,
            'successful_files': successful_files,
            'failed_files': failed_files,
            'results': results,
            'total_processing_time': total_processing_time,
            'mode': mode
        }
    
    def get_progress_history(self) -> List[WorkflowProgress]:
        """é€²æ—å±¥æ­´å–å¾—"""
        return self.progress_history.copy()
    
    def reset_progress(self):
        """é€²æ—å±¥æ­´ãƒªã‚»ãƒƒãƒˆ"""
        self.progress_history.clear() 

    def process_ocr_test_from_drive(self, folder_id: str, user_id: str, max_files: int = -1) -> Dict[str, Any]:
        """
        Google Driveã®æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦OCRãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹

        Args:
            folder_id (str): Google Driveã®ãƒ•ã‚©ãƒ«ãƒ€ID
            user_id (str): å®Ÿè¡Œãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            max_files (int, optional): å‡¦ç†ã™ã‚‹æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«æ•°. Defaults to -1 (ã™ã¹ã¦).

        Returns:
            Dict[str, Any]: process_batch_files ã¨åŒã˜å½¢å¼ã®ãƒãƒƒãƒå‡¦ç†çµæœ
        """
        self._notify_progress(WorkflowStatus.PROCESSING, "OCR_TEST_PREPARATION", 5, f"Google Driveãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—é–‹å§‹: {folder_id}")

        try:
            # 1. Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
            if not self.storage_service:
                raise ValueError("Storage service (Google Drive) is not configured.")
            
            from utils.ocr_test_helper import OCRTestManager
            ocr_manager = OCRTestManager(self.storage_service, None, None)
            pdf_files = ocr_manager.get_drive_pdfs(folder_id)

            if not pdf_files:
                logger.warning(f"æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {folder_id}")
                return {"error": f"No PDF files found in folder {folder_id}", "results": [], "total_files": 0, "successful_files": 0, "failed_files": 0}

            # 2. ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™
            if max_files != -1 and len(pdf_files) > max_files:
                pdf_files = pdf_files[:max_files]
            
            self._notify_progress(WorkflowStatus.PROCESSING, "OCR_TEST_PREPARATION", 10, f"{len(pdf_files)}ä»¶ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™")

            # 3. ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
            files_data = []
            for i, file_info in enumerate(pdf_files):
                try:
                    progress = 10 + int((i / len(pdf_files)) * 20) # 10%-30%
                    self._notify_progress(WorkflowStatus.PROCESSING, "FILE_DOWNLOAD", progress, f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ ({i+1}/{len(pdf_files)}): {file_info['name']}")
                    
                    file_data = self.storage_service.download_file(file_info['id'])
                    if file_data:
                        files_data.append({
                            'filename': file_info['name'],
                            'data': file_data
                        })
                    else:
                        logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒç©ºï¼‰: {file_info['name']}")

                except Exception as e:
                    logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ï¼‰: {file_info['name']} - {e}", exc_info=True)
            
            if not files_data:
                logger.error("å‡¦ç†å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«ã™ã¹ã¦å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return {"error": "Failed to download any processable files.", "results": [], "total_files": len(pdf_files), "successful_files": 0, "failed_files": len(pdf_files)}

            # 4. æ—¢å­˜ã®ãƒãƒƒãƒå‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
            self._notify_progress(WorkflowStatus.PROCESSING, "BATCH_PROCESSING_START", 30, "AIã«ã‚ˆã‚‹ä¸€æ‹¬è§£æå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
            return self.process_batch_files(
                files_data=files_data,
                user_id=user_id,
                mode="ocr_test"
            )

        except Exception as e:
            logger.error(f"OCRãƒ†ã‚¹ãƒˆæº–å‚™ãƒ•ã‚§ãƒ¼ã‚ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
            self._notify_progress(WorkflowStatus.FAILED, "OCR_TEST_PREPARATION", 0, f"OCRãƒ†ã‚¹ãƒˆæº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": f"An error occurred during OCR test preparation: {e}"} 