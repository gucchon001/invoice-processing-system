"""
OCRãƒ†ã‚¹ãƒˆãƒ˜ãƒ«ãƒ‘ãƒ¼ - Geminiã‚’ä½¿ç”¨ã—ãŸPDFå‡¦ç†ãƒ†ã‚¹ãƒˆ

Google Driveã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã€Geminiã§OCRå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import streamlit as st
import pandas as pd
import json
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime, timezone, timedelta
import io
import uuid

# è¨­å®šãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.config_helper import get_gemini_model

# çµ±ä¸€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from core.services.invoice_validator import InvoiceValidator

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

# æ—¥æ™‚ã‚’UTCã‹ã‚‰JSTã«å¤‰æ›ã™ã‚‹é–¢æ•°ã‚’è¿½åŠ 
def convert_utc_to_jst(utc_time_str: str) -> str:
    """UTCæ™‚åˆ»æ–‡å­—åˆ—ã‚’JSTï¼ˆæ—¥æœ¬æ¨™æº–æ™‚ï¼‰ã«å¤‰æ›"""
    try:
        if not utc_time_str:
            return ""
        
        # UTCæ™‚åˆ»ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã‚’è€ƒæ…®ï¼‰
        if utc_time_str.endswith('Z'):
            utc_time = datetime.fromisoformat(utc_time_str[:-1] + '+00:00')
        elif '+' in utc_time_str or utc_time_str.endswith('T'):
            utc_time = datetime.fromisoformat(utc_time_str)
        else:
            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãŒãªã„å ´åˆã¯UTCã¨ã—ã¦æ‰±ã†
            utc_time = datetime.fromisoformat(utc_time_str).replace(tzinfo=timezone.utc)
        
        # JSTã«å¤‰æ›ï¼ˆUTC+9ï¼‰
        jst = utc_time.astimezone(timezone(timedelta(hours=9)))
        
        # è¡¨ç¤ºç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆYYYY-MM-DD HH:MMï¼‰
        return jst.strftime('%Y-%m-%d %H:%M')
        
    except Exception as e:
        logger.warning(f"æ—¥æ™‚å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}, å…ƒã®å€¤: {utc_time_str}")
        return str(utc_time_str)[:16]  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å…ƒã®å‡¦ç†

class OCRTestManager:
    """OCRãƒ†ã‚¹ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, drive_manager, gemini_manager, database_manager=None):
        """åˆæœŸåŒ–"""
        self.drive_manager = drive_manager
        self.gemini_manager = gemini_manager
        self.database_manager = database_manager
        # çµ±ä¸€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self.validator = InvoiceValidator()
        
    def get_drive_pdfs(self, folder_id: str) -> List[Dict[str, Any]]:
        """Google Driveãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            logger.info(f"ãƒ•ã‚©ãƒ«ãƒ€ID {folder_id} ã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ä¸­...")
            
            # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆå…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–å¯¾å¿œï¼‰
            query = f"'{folder_id}' in parents and mimeType='application/pdf' and trashed=false"
            
            results = self.drive_manager.service.files().list(
                q=query,
                fields="files(id, name, size, modifiedTime)",
                orderBy="modifiedTime desc",
                supportsAllDrives=True,
                includeItemsFromAllDrives=True
            ).execute()
            
            files = results.get('files', [])
            logger.info(f"{len(files)}å€‹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            
            return files
            
        except Exception as e:
            logger.error(f"Google Driveã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            st.error(f"PDFãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def download_pdf_from_drive(self, file_id: str) -> Optional[bytes]:
        """Google Driveã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ID {file_id} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            
            request = self.drive_manager.service.files().get_media(
                fileId=file_id,
                supportsAllDrives=True
            )
            file_content = io.BytesIO()
            
            import googleapiclient.http
            downloader = googleapiclient.http.MediaIoBaseDownload(file_content, request)
            
            done = False
            while done is False:
                status, done = downloader.next_chunk()
                
            file_content.seek(0)
            content = file_content.read()
            
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(content)} bytes")
            return content
            
        except Exception as e:
            logger.error(f"Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def create_ocr_prompt(self, filename: str = "", file_size: int = 0) -> str:
        """OCRç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆï¼ˆJSONå¤–å‡ºã—å¯¾å¿œï¼‰"""
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨ã—ã¦JSONå¤–å‡ºã—ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿
            from utils.prompt_manager import get_prompt_manager
            
            prompt_manager = get_prompt_manager()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ä½œæˆ
            file_info = f"è«‹æ±‚æ›¸PDFãƒ•ã‚¡ã‚¤ãƒ«: {filename}"
            if file_size > 0:
                file_info += f" (ã‚µã‚¤ã‚º: {file_size:,} bytes)"
            
            # OCRæŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æä¾›ï¼‰
            ocr_prompt = prompt_manager.render_prompt(
                "invoice_extractor_prompt",
                {
                    "extraction_mode": "comprehensive",
                    "invoice_image": file_info  # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æä¾›
                }
            )
            
            logger.info(f"JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦OCRãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ: {filename}")
            return ocr_prompt
            
        except Exception as e:
            logger.error(f"JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
            logger.warning("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¬ã‚¬ã‚·ãƒ¼OCRãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")
            return self._create_ocr_prompt_legacy()
    
    def _create_ocr_prompt_legacy(self) -> str:
        """OCRç”¨ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
        return """
ã‚ãªãŸã¯è«‹æ±‚æ›¸ã®OCRå°‚é–€å®¶ã§ã™ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚

## æŠ½å‡ºå¯¾è±¡é …ç›®ï¼š
1. **è«‹æ±‚å…ƒä¼æ¥­å** (issuer_name)
2. **è«‹æ±‚å…ˆä¼æ¥­å** (recipient_name)  
3. **é ˜åæ›¸ç•ªå·** (receipt_number)
4. **è«‹æ±‚æ›¸ç•ªå·** (invoice_number)
5. **ç™»éŒ²ç•ªå·** (registration_number)
6. **é€šè²¨** (currency) - JPY, USD, EURç­‰
7. **ç¨è¾¼é‡‘é¡** (total_amount_tax_included) - æ•°å€¤ã®ã¿
8. **ç¨æŠœé‡‘é¡** (total_amount_tax_excluded) - æ•°å€¤ã®ã¿
9. **ç™ºè¡Œæ—¥** (issue_date) - YYYY-MM-DDå½¢å¼
10. **æ”¯æ‰•æœŸæ—¥** (due_date) - YYYY-MM-DDå½¢å¼
11. **æ˜ç´°** (line_items) - å„æ˜ç´°ã®é…åˆ—
12. **ã‚­ãƒ¼æƒ…å ±** (key_info) - æ”¯æ‰•ãƒã‚¹ã‚¿ç…§åˆç”¨ã®é‡è¦æƒ…å ±

## æ˜ç´°ã®æ§‹é€ ï¼š
```json
{
  "description": "å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹å",
  "quantity": æ•°é‡,
  "unit_price": å˜ä¾¡,
  "amount": é‡‘é¡,
  "tax": "ç¨ç‡(10%ç­‰)"
}
```

## æ³¨æ„äº‹é …ï¼š
- æ•°å€¤ã¯å¿…ãšæ•°å€¤å‹ã§è¿”ã™ï¼ˆæ–‡å­—åˆ—ä¸å¯ï¼‰
- æ—¥ä»˜ã¯YYYY-MM-DDå½¢å¼ã§çµ±ä¸€
- ä¸æ˜ãªé …ç›®ã¯nullã‚’è¨­å®š
- æ˜ç´°ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯é…åˆ—ã§å…¨ã¦æŠ½å‡º
- é€šè²¨è¨˜å·ã¯é™¤å»ã—ã€é€šè²¨ã‚³ãƒ¼ãƒ‰ã®ã¿è¨˜è¼‰

## å‡ºåŠ›å½¢å¼ï¼š
```json
{
  "issuer_name": "æ ªå¼ä¼šç¤¾â—‹â—‹",
  "recipient_name": "æ ªå¼ä¼šç¤¾â–³â–³", 
  "receipt_number": "REC-2024-001",
  "invoice_number": "INV-2024-001",
  "registration_number": "T1234567890123",
  "currency": "JPY",
  "total_amount_tax_included": 110000,
  "total_amount_tax_excluded": 100000,
  "issue_date": "2024-12-01",
  "due_date": "2024-12-31",
  "key_info": {
    "payee": "æ ªå¼ä¼šç¤¾â–³â–³",
    "content": "ã‚µãƒ¼ãƒ“ã‚¹å",
    "special_conditions": [],
    "confidence_score": 0.95
  },
  "line_items": [
    {
      "description": "ã‚µãƒ¼ãƒ“ã‚¹å",
      "quantity": 1,
      "unit_price": 100000,
      "amount": 100000,
      "tax": "10%"
    }
  ]
}
```

PDFã®å†…å®¹ã‚’è©³ç´°ã«åˆ†æã—ã€ä¸Šè¨˜ã®JSONå½¢å¼ã§çµæœã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
"""

    def process_pdf_with_gemini(self, pdf_content: bytes, filename: str) -> Optional[Dict[str, Any]]:
        """Geminiã§PDFã‚’OCRå‡¦ç†"""
        try:
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
            current_model = get_gemini_model()
            logger.info(f"{current_model}ã§OCRå‡¦ç†é–‹å§‹: {filename}")
            
            # OCRç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æ¸¡ã™ï¼‰
            file_size = len(pdf_content)
            prompt = self.create_ocr_prompt(filename, file_size)
            
            # Gemini APIã§å‡¦ç†
            result = self.gemini_manager.analyze_pdf_content(pdf_content, prompt)
            
            if result:
                logger.info(f"OCRå‡¦ç†å®Œäº†: {filename}")
                return result
            else:
                logger.error(f"OCRå‡¦ç†å¤±æ•—: {filename}")
                return None
                
        except Exception as e:
            logger.error(f"Gemini OCRå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ ({filename}): {e}")
            st.error(f"OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def validate_ocr_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """OCRçµæœã®è©³ç´°æ¤œè¨¼ï¼ˆçµ±åˆç‰ˆãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ï¼‰"""
        try:
            # çµ±ä¸€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            validation = self.validator.validate_invoice_data(result, strict_mode=False)
            
            # OCRãƒ†ã‚¹ãƒˆç”¨ã®å®Œå…¨æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—ã‚’è¿½åŠ 
            if "completeness_score" not in validation:
                required_fields = {"issuer", "amount_inclusive_tax", "currency"}
                important_fields = {"payer", "main_invoice_number", "issue_date"}
                optional_fields = {"t_number", "amount_exclusive_tax", "due_date", "line_items", "key_info"}
                all_fields = required_fields | important_fields | optional_fields
                
                filled_fields = sum(1 for field in all_fields if self._is_valid_field_value(result.get(field)))
                validation["completeness_score"] = round((filled_fields / len(all_fields)) * 100, 1)
            
            logger.info(f"çµ±åˆãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: ã‚¨ãƒ©ãƒ¼{len(validation.get('errors', []))}ä»¶, è­¦å‘Š{len(validation.get('warnings', []))}ä»¶")
            return validation
            
        except Exception as e:
            logger.error(f"çµ±åˆãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªæ¤œè¨¼çµæœã‚’è¿”ã™
            return {
                "is_valid": False,
                "errors": [f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}"],
                "warnings": [],
                "completeness_score": 0,
                "error_categories": {
                    "critical": [f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}"],
                    "data_missing": [],
                    "data_format": [],
                    "business_logic": []
                }
            }
    
    def _is_valid_field_value(self, value) -> bool:
        """ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã®æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        if value is None:
            return False
        if isinstance(value, str) and value.strip() == "":
            return False
        if isinstance(value, (list, dict)) and len(value) == 0:
            return False
        return True

    
    def format_ocr_result_for_display(self, result: Dict[str, Any], validation: Dict[str, Any]) -> pd.DataFrame:
        """OCRçµæœã‚’è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›"""
        
        # åŸºæœ¬æƒ…å ±ï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
        basic_info = []
        field_mapping = {
            "issuer": "è«‹æ±‚å…ƒä¼æ¥­å",
            "payer": "è«‹æ±‚å…ˆä¼æ¥­å", 
            "receipt_number": "é ˜åæ›¸ç•ªå·",
            "main_invoice_number": "è«‹æ±‚æ›¸ç•ªå·",
            "t_number": "ç™»éŒ²ç•ªå·",
            "currency": "é€šè²¨",
            "amount_inclusive_tax": "ç¨è¾¼é‡‘é¡",
            "amount_exclusive_tax": "ç¨æŠœé‡‘é¡",
            "issue_date": "ç™ºè¡Œæ—¥",
            "due_date": "æ”¯æ‰•æœŸæ—¥",
            "key_info": "ã‚­ãƒ¼æƒ…å ±"
        }
        
        for field, label in field_mapping.items():
            value = result.get(field, "")
            if value is None:
                value = ""
            basic_info.append({
                "é …ç›®": label,
                "å€¤": str(value),
                "ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å": field
            })
        
        df_basic = pd.DataFrame(basic_info)
        
        # æ˜ç´°æƒ…å ±
        line_items = result.get("line_items", [])
        df_details = pd.DataFrame()
        
        # line_itemsã®å®‰å…¨ãªå‡¦ç†
        if not isinstance(line_items, list):
            line_items = []
        
        if len(line_items) > 0:
            details_data = []
            for i, item in enumerate(line_items, 1):
                details_data.append({
                    "No.": i,
                    "å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹å": item.get("description", ""),
                    "æ•°é‡": item.get("quantity", ""),
                    "å˜ä¾¡": item.get("unit_price", ""),
                    "é‡‘é¡": item.get("amount", ""),
                    "ç¨ç‡": item.get("tax", "")
                })
            df_details = pd.DataFrame(details_data)
        
        return df_basic, df_details
    
    def run_comprehensive_test(self, folder_id: str, max_files: int = -1) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„OCRãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        test_results = {
            "start_time": datetime.now(),
            "folder_id": folder_id,
            "files_processed": 0,
            "files_success": 0,
            "files_failed": 0,
            "results": [],
            "summary": {}
        }
        
        try:
            # PDFãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
            pdf_files = self.get_drive_pdfs(folder_id)
            
            # DataFrameã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
            if hasattr(pdf_files, 'to_dict'):
                pdf_files = pdf_files.to_dict('records')
            elif not isinstance(pdf_files, list):
                pdf_files = []
            
            if len(pdf_files) == 0:
                st.warning("æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return test_results
            
            # ä»¶æ•°åˆ¶é™ã‚’é©ç”¨
            if max_files > 0:
                pdf_files = pdf_files[:max_files]
                st.info(f"{len(pdf_files)}å€‹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼ˆåˆ¶é™: {max_files}ä»¶ï¼‰")
            else:
                st.info(f"{len(pdf_files)}å€‹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆå…¨ä»¶ãƒ†ã‚¹ãƒˆï¼‰")
            
            # é€²æ—ãƒãƒ¼è¨­å®š
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«IDãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            if "file_id_mapping" not in st.session_state:
                st.session_state.file_id_mapping = {}
            
            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            for i, file_info in enumerate(pdf_files):
                file_id = file_info["id"]
                filename = file_info["name"]
                
                # ãƒ•ã‚¡ã‚¤ãƒ«IDãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿å­˜ï¼ˆåŸæœ¬è¡¨ç¤ºç”¨ï¼‰
                st.session_state.file_id_mapping[filename] = file_id
                
                status_text.text(f"å‡¦ç†ä¸­: {filename} ({i+1}/{len(pdf_files)})")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                pdf_content = self.download_pdf_from_drive(file_id)
                
                if pdf_content:
                    # OCRå‡¦ç†
                    ocr_result = self.process_pdf_with_gemini(pdf_content, filename)
                    
                    if ocr_result:
                        # çµæœæ¤œè¨¼
                        validation = self.validate_ocr_result(ocr_result)
                        
                        test_results["results"].append({
                            "file_id": file_id,
                            "filename": filename,
                            "file_size": file_info.get("size", 0),
                            "ocr_result": ocr_result,
                            "validation": validation,
                            "processed_at": datetime.now().isoformat()
                        })
                        
                        # æ¤œè¨¼çµæœã«åŸºã¥ã„ã¦æˆåŠŸã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                        if validation["is_valid"]:
                            test_results["files_success"] += 1
                        else:
                            test_results["files_failed"] += 1
                    else:
                        test_results["files_failed"] += 1
                else:
                    test_results["files_failed"] += 1
                
                test_results["files_processed"] += 1
                
                # é€²æ—æ›´æ–°
                progress = (i + 1) / len(pdf_files)
                progress_bar.progress(progress)
            
            # ã‚µãƒãƒªãƒ¼è¨ˆç®—
            test_results["end_time"] = datetime.now()
            test_results["duration"] = (test_results["end_time"] - test_results["start_time"]).total_seconds()
            
            if len(test_results.get("results", [])) > 0:
                # Noneå€¤ã‚’é™¤å¤–ã—ã¦æœ‰åŠ¹ãªã‚¹ã‚³ã‚¢ã®ã¿ã‚’å–å¾—
                completeness_scores = [
                    r["validation"]["completeness_score"] 
                    for r in test_results["results"] 
                    if r["validation"]["completeness_score"] is not None
                ]
                
                if completeness_scores:
                    test_results["summary"] = {
                        "average_completeness": round(sum(completeness_scores) / len(completeness_scores), 1),
                        "min_completeness": min(completeness_scores),
                        "max_completeness": max(completeness_scores),
                        "success_rate": round((test_results["files_success"] / test_results["files_processed"]) * 100, 1)
                    }
                else:
                    test_results["summary"] = {
                        "average_completeness": 0.0,
                        "min_completeness": 0.0,
                        "max_completeness": 0.0,
                        "success_rate": round((test_results["files_success"] / test_results["files_processed"]) * 100, 1)
                    }
            
            status_text.text("å‡¦ç†å®Œäº†!")
            progress_bar.progress(1.0)
            
        except Exception as e:
            logger.error(f"åŒ…æ‹¬çš„OCRãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            st.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return test_results
    
    def save_to_supabase(self, test_results: Dict[str, Any], user_email: str) -> Optional[str]:
        """ãƒ†ã‚¹ãƒˆçµæœã‚’Supabaseã«ä¿å­˜"""
        if not self.database_manager:
            logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        try:
            # Service Role Keyã‚’ä½¿ç”¨ã—ã¦RLSå›é¿
            try:
                import streamlit as st
                service_key = st.secrets["database"]["supabase_service_key"]
                supabase_url = st.secrets["database"]["supabase_url"]
                
                from supabase import create_client
                service_supabase = create_client(supabase_url, service_key)
                
                logger.info("Service Role Keyã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ä¿å­˜")
                
            except Exception as e:
                logger.warning(f"Service Role Keyä½¿ç”¨å¤±æ•—ã€é€šå¸¸ã‚­ãƒ¼ã§è©¦è¡Œ: {e}")
                service_supabase = self.database_manager.supabase
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿å­˜
            session_data = {
                "session_name": f"OCRãƒ†ã‚¹ãƒˆ_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "folder_id": test_results["folder_id"],
                "total_files": test_results["files_processed"],
                "processed_files": test_results["files_processed"],
                "success_files": test_results["files_success"],
                "failed_files": test_results["files_failed"],
                "average_completeness": test_results.get("summary", {}).get("average_completeness"),
                "success_rate": test_results.get("summary", {}).get("success_rate"),
                "processing_duration": test_results.get("duration"),
                "created_by": user_email
            }
            
            session_response = service_supabase.table("ocr_test_sessions").insert(session_data).execute()
            
            if not session_response.data:
                logger.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
            
            session_id = session_response.data[0]["id"]
            logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜å®Œäº†: {session_id}")
            
            # å„çµæœã‚’ä¿å­˜
            for result in test_results.get("results", []):
                ocr_result = result["ocr_result"]
                validation = result["validation"]
                
                # çµæœãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
                result_data = {
                    "session_id": session_id,
                    "file_id": result["file_id"],
                    "filename": result["filename"],
                    "file_size": result.get("file_size"),
                    "issuer_name": ocr_result.get("issuer"),                    # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "recipient_name": ocr_result.get("payer"),                  # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "receipt_number": ocr_result.get("receipt_number"),
                    "invoice_number": ocr_result.get("main_invoice_number"),    # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "registration_number": ocr_result.get("t_number"),          # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "currency": ocr_result.get("currency"),
                    "total_amount_tax_included": ocr_result.get("amount_inclusive_tax"),  # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "total_amount_tax_excluded": ocr_result.get("amount_exclusive_tax"),  # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "issue_date": ocr_result.get("issue_date"),
                    "due_date": ocr_result.get("due_date"),
                    "key_info": ocr_result.get("key_info"),
                    "is_valid": validation["is_valid"],
                    "completeness_score": validation["completeness_score"],
                    "validation_errors": validation["errors"],
                    "validation_warnings": validation["warnings"],
                    "processing_time": 8.5,  # å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²
                    "raw_response": ocr_result
                }
                
                # çµæœã‚’ä¿å­˜
                result_response = service_supabase.table("ocr_test_results").insert(result_data).execute()
                
                if result_response.data:
                    result_id = result_response.data[0]["id"]
                    
                    # æ˜ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                    line_items = ocr_result.get("line_items", [])
                    for i, item in enumerate(line_items, 1):
                        # ç¨ç‡ãƒ‡ãƒ¼ã‚¿ã®æ•°å€¤å¤‰æ›ï¼ˆ"10%" â†’ 10.0ï¼‰
                        tax_rate = item.get("tax")
                        if tax_rate and isinstance(tax_rate, str):
                            # "%"ã‚’é™¤å»ã—ã¦æ•°å€¤ã«å¤‰æ›
                            try:
                                if "%" in tax_rate:
                                    tax_rate = float(tax_rate.replace("%", "").strip())
                                else:
                                    tax_rate = float(tax_rate)
                            except (ValueError, AttributeError):
                                tax_rate = None
                        
                        line_item_data = {
                            "result_id": result_id,
                            "line_number": i,
                            "item_description": item.get("description"),
                            "quantity": item.get("quantity"),
                            "unit_price": item.get("unit_price"),
                            "amount": item.get("amount"),
                            "tax_rate": tax_rate
                        }
                        
                        service_supabase.table("ocr_test_line_items").insert(line_item_data).execute()
            
            logger.info(f"å…¨ãƒ†ã‚¹ãƒˆçµæœã‚’Supabaseã«ä¿å­˜å®Œäº†: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID {session_id}")
            return session_id
            
        except Exception as e:
            logger.error(f"Supabaseã¸ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ç‰¹åˆ¥ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if "does not exist" in str(e) or "relation" in str(e):
                st.warning("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæœªä½œæˆã®ãŸã‚ã€çµæœã‚’ä¿å­˜ã§ãã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
                logger.info("OCRãƒ†ã‚¹ãƒˆç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæœªä½œæˆã®ãŸã‚ã€çµæœä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            else:
                st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def load_sessions_from_supabase(self, user_email: str) -> List[Dict[str, Any]]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®OCRãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—"""
        if not self.database_manager:
            return []
        
        try:
            # Service Role Keyã‚’ä½¿ç”¨ã—ã¦RLSå›é¿
            try:
                import streamlit as st
                service_key = st.secrets["database"]["supabase_service_key"]
                supabase_url = st.secrets["database"]["supabase_url"]
                
                from supabase import create_client
                service_supabase = create_client(supabase_url, service_key)
                
                logger.info("Service Role Keyã‚’ä½¿ç”¨ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´å–å¾—")
                
            except Exception as e:
                logger.warning(f"Service Role Keyä½¿ç”¨å¤±æ•—ã€é€šå¸¸ã‚­ãƒ¼ã§è©¦è¡Œ: {e}")
                service_supabase = self.database_manager.supabase
            
            response = service_supabase.table("ocr_test_sessions").select("*").eq("created_by", user_email).order("created_at", desc=True).execute()
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªå‡¦ç†
            data = response.data if response.data else []
            
            # DataFrameã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
            if hasattr(data, 'to_dict'):
                data = data.to_dict('records')
            elif not isinstance(data, list):
                data = []
            
            return data
            
        except Exception as e:
            logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
            if "does not exist" in str(e) or "relation" in str(e):
                logger.info("OCRãƒ†ã‚¹ãƒˆç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæœªä½œæˆã®ãŸã‚ã€å±¥æ­´ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“")
            return []
    
    def load_session_results(self, session_id: str) -> List[Dict[str, Any]]:
        """ç‰¹å®šã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµæœã‚’å–å¾—"""
        if not self.database_manager:
            return []
        
        try:
            # Service Role Keyã‚’ä½¿ç”¨ã—ã¦RLSå›é¿
            try:
                import streamlit as st
                service_key = st.secrets["database"]["supabase_service_key"]
                supabase_url = st.secrets["database"]["supabase_url"]
                
                from supabase import create_client
                service_supabase = create_client(supabase_url, service_key)
                
                logger.info("Service Role Keyã‚’ä½¿ç”¨ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœå–å¾—")
                
            except Exception as e:
                logger.warning(f"Service Role Keyä½¿ç”¨å¤±æ•—ã€é€šå¸¸ã‚­ãƒ¼ã§è©¦è¡Œ: {e}")
                service_supabase = self.database_manager.supabase
            
            # çµæœã¨ãã®æ˜ç´°ã‚’çµåˆã—ã¦å–å¾—
            response = service_supabase.table("ocr_test_results").select(
                "*, ocr_test_line_items(*)"
            ).eq("session_id", session_id).execute()
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªå‡¦ç†
            data = response.data if response.data else []
            
            # DataFrameã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
            if hasattr(data, 'to_dict'):
                data = data.to_dict('records')
            elif not isinstance(data, list):
                data = []
            
            # ãƒ•ã‚¡ã‚¤ãƒ«IDãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å¾©å…ƒï¼ˆåŸæœ¬è¡¨ç¤ºç”¨ï¼‰
            if "file_id_mapping" not in st.session_state:
                st.session_state.file_id_mapping = {}
            
            for record in data:
                filename = record.get("filename", "")
                file_id = record.get("file_id", "")
                if filename and file_id:
                    st.session_state.file_id_mapping[filename] = file_id
            
            return data
            
        except Exception as e:
            logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœèª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def display_line_items(self, data_source: Dict, title: str = "ğŸ“‹ æ˜ç´°æƒ…å ±") -> None:
        """æ˜ç´°æƒ…å ±ã‚’ag-gridã§è¡¨ç¤ºã™ã‚‹å…±é€šãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            data_source: line_itemsã‚’å«ã‚€è¾æ›¸ãƒ‡ãƒ¼ã‚¿ (ocr_result ã¾ãŸã¯ raw_response)
            title: è¡¨ç¤ºã‚¿ã‚¤ãƒˆãƒ«
        """
        # DataFrameã®å ´åˆã¯è¾æ›¸ã«å¤‰æ›
        if hasattr(data_source, 'to_dict'):
            data_source = data_source.to_dict()
        elif not isinstance(data_source, dict):
            data_source = {}
        
        # æ˜ç´°æƒ…å ±ã‚’å–å¾—
        line_items = data_source.get("line_items", [])
        if not isinstance(line_items, list):
            line_items = []
        
        if len(line_items) > 0:
            st.markdown(f"### {title}")
            line_items_df = pd.DataFrame([
                {
                    "No.": i+1,
                    "å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹å": item.get("description", ""),
                    "æ•°é‡": item.get("quantity", ""),
                    "å˜ä¾¡": item.get("unit_price", ""),
                    "é‡‘é¡": item.get("amount", ""),
                    "ç¨ç‡": item.get("tax", "")
                }
                for i, item in enumerate(line_items)
            ])
            
            # ag-gridã§æ˜ç´°è¡¨ç¤º
            try:
                from infrastructure.ui.aggrid_helper import get_aggrid_manager
                aggrid_manager = get_aggrid_manager()
                aggrid_manager.create_data_grid(
                    line_items_df,
                    editable=False,
                    fit_columns_on_grid_load=True,
                    height=200
                )
            except ImportError:
                # ag-gridãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯æ¨™æº–è¡¨ç¤º
                st.dataframe(line_items_df, use_container_width=True)
            except Exception as e:
                st.error(f"æ˜ç´°è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.dataframe(line_items_df, use_container_width=True)
        else:
            st.info(f"{title}: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯æ˜ç´°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    def display_invoice_basic_info(self, data_source: Dict, data_type: str = "new") -> None:
        """è«‹æ±‚æ›¸åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹å…±é€šãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            data_source: OCRçµæœã‚’å«ã‚€è¾æ›¸ãƒ‡ãƒ¼ã‚¿
            data_type: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— ("new": æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆ, "history": å±¥æ­´ãƒ‡ãƒ¼ã‚¿)
        """
        st.markdown("**åŸºæœ¬æƒ…å ±**")
        
        if data_type == "new":
            # æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆçµæœã®å ´åˆ
            ocr_result = data_source.get("ocr_result", {})
            
            # åŸºæœ¬ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é †åºä»˜ãã§è¡¨ç¤ºï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
            basic_fields = [
                ("issuer", "è«‹æ±‚å…ƒ"),
                ("payer", "è«‹æ±‚å…ˆ"),
                ("main_invoice_number", "è«‹æ±‚æ›¸ç•ªå·"),
                ("amount_inclusive_tax", "ç¨è¾¼é‡‘é¡"),
                ("currency", "é€šè²¨"),
                ("issue_date", "ç™ºè¡Œæ—¥")
            ]
            
            for field_key, field_label in basic_fields:
                value = ocr_result.get(field_key, "")
                if field_key == "amount_inclusive_tax" and value:
                    try:
                        amount = float(value)
                        st.write(f"â€¢ **{field_label}**: {amount:,.0f}å††")
                    except (ValueError, TypeError):
                        st.write(f"â€¢ **{field_label}**: {value}")
                else:
                    st.write(f"â€¢ **{field_label}**: {value}")
                    
        elif data_type == "history":
            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
            st.write(f"â€¢ **è«‹æ±‚å…ƒ**: {data_source.get('issuer_name', '')}")
            st.write(f"â€¢ **è«‹æ±‚å…ˆ**: {data_source.get('recipient_name', '')}")
            st.write(f"â€¢ **è«‹æ±‚æ›¸ç•ªå·**: {data_source.get('invoice_number', '')}")
            
            amount = data_source.get('total_amount_tax_included', 0)
            try:
                amount_float = float(amount)
                st.write(f"â€¢ **ç¨è¾¼é‡‘é¡**: {amount_float:,.0f}å††")
            except (ValueError, TypeError):
                st.write(f"â€¢ **ç¨è¾¼é‡‘é¡**: {amount}")
                
            st.write(f"â€¢ **é€šè²¨**: {data_source.get('currency', '')}")
            st.write(f"â€¢ **ç™ºè¡Œæ—¥**: {data_source.get('issue_date', '')}")

    def display_validation_results(self, data_source: Dict, data_type: str = "new") -> None:
        """æ¤œè¨¼çµæœã‚’è¡¨ç¤ºã™ã‚‹å…±é€šãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            data_source: æ¤œè¨¼çµæœã‚’å«ã‚€è¾æ›¸ãƒ‡ãƒ¼ã‚¿
            data_type: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— ("new": æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆ, "history": å±¥æ­´ãƒ‡ãƒ¼ã‚¿)
        """
        st.markdown("**æ¤œè¨¼çµæœ**")
        
        if data_type == "new":
            # æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆçµæœã®å ´åˆ
            validation = data_source.get("validation", {})
            is_valid = validation.get("is_valid", False)
            completeness_score = validation.get("completeness_score", 0)
            
            st.write(f"â€¢ **æ¤œè¨¼çŠ¶æ³**: {'âœ… æ­£å¸¸' if is_valid else 'âŒ ã‚¨ãƒ©ãƒ¼'}")
            st.write(f"â€¢ **å®Œå…¨æ€§ã‚¹ã‚³ã‚¢**: {completeness_score:.1f}%")
            
            # ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šè¡¨ç¤º
            errors = validation.get("errors", [])
            warnings = validation.get("warnings", [])
            
            if errors:
                st.write("â€¢ **ã‚¨ãƒ©ãƒ¼**:")
                for error in errors:
                    st.write(f"  - {error}")
            
            if warnings:
                st.write("â€¢ **è­¦å‘Š**:")
                for warning in warnings:
                    st.write(f"  - {warning}")
                    
        elif data_type == "history":
            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
            is_valid = data_source.get("is_valid", False)
            completeness_score = data_source.get("completeness_score", 0)
            
            st.write(f"â€¢ **æ¤œè¨¼çŠ¶æ³**: {'âœ… æ­£å¸¸' if is_valid else 'âŒ ã‚¨ãƒ©ãƒ¼'}")
            st.write(f"â€¢ **å®Œå…¨æ€§ã‚¹ã‚³ã‚¢**: {completeness_score:.1f}%")
            
            # ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šè¡¨ç¤ºï¼ˆå±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
            validation_errors = data_source.get("validation_errors", [])
            validation_warnings = data_source.get("validation_warnings", [])
            
            # DataFrameã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
            if hasattr(validation_errors, 'tolist'):
                validation_errors = validation_errors.tolist()
            elif hasattr(validation_errors, 'to_dict'):
                validation_errors = validation_errors.to_dict('records')
            elif not isinstance(validation_errors, list):
                validation_errors = []
            
            if hasattr(validation_warnings, 'tolist'):
                validation_warnings = validation_warnings.tolist()
            elif hasattr(validation_warnings, 'to_dict'):
                validation_warnings = validation_warnings.to_dict('records')
            elif not isinstance(validation_warnings, list):
                validation_warnings = []
            
            if len(validation_errors) > 0:
                st.write("â€¢ **ã‚¨ãƒ©ãƒ¼**:")
                for error in validation_errors:
                    st.write(f"  - {error}")
            
            if len(validation_warnings) > 0:
                st.write("â€¢ **è­¦å‘Š**:")
                for warning in validation_warnings:
                    st.write(f"  - {warning}")

    def display_invoice_details(self, data_source: Dict, data_type: str = "new", show_line_items: bool = True, show_json: bool = True, show_original: bool = True) -> None:
        """è«‹æ±‚æ›¸è©³ç´°æƒ…å ±ã‚’çµ±åˆè¡¨ç¤ºã™ã‚‹å…±é€šãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            data_source: è«‹æ±‚æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¾æ›¸
            data_type: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— ("new": æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆ, "history": å±¥æ­´ãƒ‡ãƒ¼ã‚¿)
            show_line_items: æ˜ç´°è¡¨ç¤ºã®æœ‰ç„¡
            show_json: JSONè¡¨ç¤ºã®æœ‰ç„¡
            show_original: åŸæœ¬è¡¨ç¤ºã®æœ‰ç„¡
        """
        col1, col2 = st.columns(2)
        
        with col1:
            self.display_invoice_basic_info(data_source, data_type)
        
        with col2:
            self.display_validation_results(data_source, data_type)
        
        if show_line_items:
            # æ˜ç´°è¡¨ç¤º
            st.markdown("---")
            if data_type == "new":
                ocr_result = data_source.get("ocr_result", {})
                self.display_line_items(ocr_result, "ğŸ“‹ æ˜ç´°æƒ…å ±")
            elif data_type == "history":
                raw_response = data_source.get("raw_response", {})
                self.display_line_items(raw_response, "ğŸ“‹ æ˜ç´°æƒ…å ±")
        
        if show_json:
            # JSONè¡¨ç¤º
            st.markdown("---")
            self.display_json_data(data_source, data_type)
        
        if show_original:
            # åŸæœ¬è¡¨ç¤º
            st.markdown("---")
            self.display_original_document(data_source, data_type)

    def display_json_data(self, data_source: Dict, data_type: str = "new") -> None:
        """JSONå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã™ã‚‹å…±é€šãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            data_source: è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            data_type: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— ("new": æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆ, "history": å±¥æ­´ãƒ‡ãƒ¼ã‚¿)
        """
        st.markdown("### ğŸ“„ JSONå½¢å¼ã®OCRçµæœ")
        
        if data_type == "new":
            # æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆçµæœã®å ´åˆ
            ocr_result = data_source.get("ocr_result", {})
            validation = data_source.get("validation", {})
            
            # OCRçµæœã¨æ¤œè¨¼çµæœã‚’çµ±åˆ
            json_data = {
                "ocr_result": ocr_result,
                "validation": validation,
                "filename": data_source.get("filename", "")
            }
            
        elif data_type == "history":
            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
            raw_response = data_source.get("raw_response", {})
            
            # DataFrameã®å ´åˆã¯è¾æ›¸ã«å¤‰æ›
            if hasattr(raw_response, 'to_dict'):
                raw_response = raw_response.to_dict()
            elif not isinstance(raw_response, dict):
                raw_response = {}
            
            json_data = {
                "filename": data_source.get("filename", ""),
                "issuer_name": data_source.get("issuer_name", ""),
                "recipient_name": data_source.get("recipient_name", ""),
                "invoice_number": data_source.get("invoice_number", ""),
                "total_amount_tax_included": data_source.get("total_amount_tax_included", 0),
                "currency": data_source.get("currency", ""),
                "issue_date": data_source.get("issue_date", ""),
                "is_valid": data_source.get("is_valid", False),
                "completeness_score": data_source.get("completeness_score", 0),
                "validation_errors": data_source.get("validation_errors", []),
                "validation_warnings": data_source.get("validation_warnings", []),
                "raw_response": raw_response
            }
        
        # JSONã‚’æ•´å½¢ã—ã¦è¡¨ç¤º
        import json
        try:
            json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
            st.code(json_str, language="json")
        except Exception as e:
            st.error(f"JSONè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.write("**Raw Data:**")
            st.write(json_data)

    def display_original_document(self, data_source: Dict, data_type: str = "new") -> None:
        """åŸæœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤ºã™ã‚‹å…±é€šãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            data_source: ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å«ã‚€è¾æ›¸
            data_type: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— ("new": æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆ, "history": å±¥æ­´ãƒ‡ãƒ¼ã‚¿)
        """
        st.markdown("### ğŸ“ åŸæœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
        
        filename = data_source.get("filename", "")
        if not filename:
            st.info("ãƒ•ã‚¡ã‚¤ãƒ«åãŒå–å¾—ã§ãã¾ã›ã‚“")
            return
        
        col1, col2 = st.columns([1, 3])
        
        with col1:
            # åŸæœ¬è¡¨ç¤ºãƒœã‚¿ãƒ³
            if st.button(f"ğŸ“„ {filename} ã‚’è¡¨ç¤º", key=f"show_original_{filename}_{data_type}"):
                st.session_state[f"show_pdf_{filename}"] = True
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨: ãƒ•ã‚¡ã‚¤ãƒ«IDãƒãƒƒãƒ”ãƒ³ã‚°ç¢ºèªãƒœã‚¿ãƒ³
            if st.button(f"ğŸ” IDãƒãƒƒãƒ”ãƒ³ã‚°ç¢ºèª", key=f"check_mapping_{filename}_{data_type}"):
                file_id_mapping = st.session_state.get("file_id_mapping", {})
                file_id = file_id_mapping.get(filename, "")
                if file_id:
                    st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ID: {file_id}")
                else:
                    st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    st.write(f"åˆ©ç”¨å¯èƒ½ãªãƒãƒƒãƒ”ãƒ³ã‚°: {list(file_id_mapping.keys())}")
        
        with col2:
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {filename}")
            if data_type == "new":
                file_size = data_source.get("file_size", 0)
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’æ•°å€¤ã«å¤‰æ›
                    size_num = float(file_size) if file_size else 0
                    st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {size_num:,.0f} bytes")
                except (ValueError, TypeError):
                    st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {file_size} bytes")
        
        # PDFè¡¨ç¤ºï¼ˆãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—çš„ãªè¡¨ç¤ºï¼‰
        if st.session_state.get(f"show_pdf_{filename}", False):
            with st.expander(f"ğŸ“„ {filename} - åŸæœ¬è¡¨ç¤º", expanded=True):
                try:
                    # Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                    if hasattr(self, 'drive_manager') and self.drive_manager:
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰Google Drive IDã‚’å–å¾—
                        file_id = self._get_file_id_from_filename(filename)
                        if file_id:
                            # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            pdf_content = self.download_pdf_from_drive(file_id)
                            if pdf_content:
                                # PDFã‚’è¡¨ç¤º
                                st.markdown("**ğŸ“„ PDFåŸæœ¬:**")
                                
                                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                                st.download_button(
                                    label="ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                    data=pdf_content,
                                    file_name=filename,
                                    mime="application/pdf",
                                    key=f"download_{filename}_{data_type}"
                                )
                                
                                # PDFãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ï¼ˆiframeä½¿ç”¨ï¼‰
                                import base64
                                base64_pdf = base64.b64encode(pdf_content).decode('utf-8')
                                pdf_display = f'''
                                <div style="border: 1px solid #ccc; border-radius: 5px; margin: 10px 0;">
                                    <iframe 
                                        src="data:application/pdf;base64,{base64_pdf}" 
                                        width="100%" 
                                        height="600px" 
                                        style="border: none;"
                                        type="application/pdf">
                                        <p>PDFã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚<a href="data:application/pdf;base64,{base64_pdf}" download="{filename}">ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>ã—ã¦ã”ç¢ºèªãã ã•ã„ã€‚</p>
                                    </iframe>
                                </div>
                                '''
                                st.markdown(pdf_display, unsafe_allow_html=True)
                                
                                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
                                st.info(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(pdf_content):,} bytes")
                            else:
                                st.error("ğŸ“¥ PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                                st.info("Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                        else:
                            st.error("ğŸ” Google Driveä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                            st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å: {filename} ã®IDãŒã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                    else:
                        st.error("ğŸ”§ Google Driveãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                        st.info("Google Driveã¨ã®æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                
                except Exception as e:
                    st.error(f"ğŸš¨ åŸæœ¬è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
                    st.info("åŸæœ¬ã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã‚’ã”ç¢ºèªãã ã•ã„ï¼š")
                    st.write("â€¢ Google Driveã¸ã®æ¥ç¶šçŠ¶æ³")
                    st.write("â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™")
                    st.write("â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¦ã„ãªã„ã‹")
                    
                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                    with st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
                        st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {filename}")
                        st.write(f"**ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—**: {data_type}")
                        st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«IDãƒãƒƒãƒ”ãƒ³ã‚°**: {st.session_state.get('file_id_mapping', {})}")
                        st.write(f"**drive_manager**: {hasattr(self, 'drive_manager')}")
                        if hasattr(self, 'drive_manager'):
                            st.write(f"**drive_manager.service**: {hasattr(self.drive_manager, 'service') if self.drive_manager else 'None'}")
                        import traceback
                        st.code(traceback.format_exc())
                
                # é–‰ã˜ã‚‹ãƒœã‚¿ãƒ³
                if st.button("âŒ é–‰ã˜ã‚‹", key=f"close_pdf_{filename}_{data_type}"):
                    st.session_state[f"show_pdf_{filename}"] = False
                    st.rerun()

    def _get_file_id_from_filename(self, filename: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰Google Drive IDã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            Google Drive ãƒ•ã‚¡ã‚¤ãƒ«ID
        """
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«IDãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ç¢ºèª
        file_id_mapping = st.session_state.get("file_id_mapping", {})
        file_id = file_id_mapping.get(filename, "")
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«IDå–å¾—: {filename} -> {file_id}")
        logger.info(f"åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«IDãƒãƒƒãƒ”ãƒ³ã‚°: {list(file_id_mapping.keys())}")
        
        return file_id

    def analyze_error_details(self, result: Dict[str, Any], validation: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼è©³ç´°åˆ†æã¨ä¿®æ­£ææ¡ˆ"""
        analysis = {
            "error_summary": {},
            "missing_fields": [],
            "correction_suggestions": [],
            "manual_review_needed": False,
            "retry_recommended": False
        }
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¬ æåˆ†æï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
        required_fields = {
            "issuer": "è«‹æ±‚å…ƒä¼æ¥­å",
            "amount_inclusive_tax": "ç¨è¾¼é‡‘é¡", 
            "currency": "é€šè²¨"
        }
        
        for field, display_name in required_fields.items():
            value = result.get(field)
            if not self._is_valid_field_value(value):
                analysis["missing_fields"].append({
                    "field": field,
                    "display_name": display_name,
                    "current_value": value,
                    "suggestion": self._get_field_correction_suggestion(field, result)
                })
        
        # ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ä¿®æ­£ææ¡ˆ
        error_categories = validation.get("error_categories", {})
        
        if error_categories.get("data_missing"):
            analysis["correction_suggestions"].append({
                "type": "prompt_improvement",
                "priority": "high",
                "description": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª¿æ•´ã—ã¦å¿…é ˆãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºç²¾åº¦ã‚’å‘ä¸Š",
                "action": "OCRãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æŒ‡ç¤ºã‚’å¼·åŒ–"
            })
            analysis["retry_recommended"] = True
        
        if error_categories.get("data_format"):
            analysis["correction_suggestions"].append({
                "type": "data_validation",
                "priority": "medium", 
                "description": "ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®æ­£è¦åŒ–å‡¦ç†ã‚’è¿½åŠ ",
                "action": "å‰å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½"
            })
        
        if error_categories.get("business_logic"):
            analysis["correction_suggestions"].append({
                "type": "business_rule",
                "priority": "low",
                "description": "ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«ã®èª¿æ•´ãŒå¿…è¦",
                "action": "å€‹åˆ¥å‡¦ç†ãƒ«ãƒ¼ãƒ«ã¾ãŸã¯ä¾‹å¤–è¨­å®šã‚’æ¤œè¨"
            })
        
        # æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå¿…è¦ã‹ã®åˆ¤å®š
        if (len(analysis["missing_fields"]) > 2 or 
            validation["completeness_score"] < 30 or
            any("critical" in str(error) for error in validation.get("errors", []))):
            analysis["manual_review_needed"] = True
        
        return analysis
    
    def _get_field_correction_suggestion(self, field: str, result: Dict[str, Any]) -> str:
        """ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ¥ã®ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰"""
        if field == "issuer":
            # ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰æ¨æ¸¬å¯èƒ½ãªæƒ…å ±ã‚’ç¢ºèª
            if result.get("key_info", {}).get("payee"):
                return f"key_info.payeeã« '{result['key_info']['payee']}' ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ä½¿ç”¨å¯èƒ½ã‹ç¢ºèª"
            return "PDFã‹ã‚‰ä¼æ¥­åã‚’æ‰‹å‹•ã§ç¢ºèªã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¼æ¥­åæŠ½å‡ºæŒ‡ç¤ºã‚’å¼·åŒ–"
        
        elif field == "amount_inclusive_tax":
            # æ˜ç´°ã‹ã‚‰æ¨æ¸¬å¯èƒ½ã‹ç¢ºèª
            line_items = result.get("line_items", [])
            if not isinstance(line_items, list):
                line_items = []
            if len(line_items) > 0:
                return "æ˜ç´°æƒ…å ±ã¯å–å¾—ã§ãã¦ã„ã¾ã™ã€‚æ˜ç´°åˆè¨ˆã‹ã‚‰ç¨è¾¼é‡‘é¡ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã‚’æ¤œè¨"
            return "é‡‘é¡æƒ…å ±ã®æŠ½å‡ºãƒ«ãƒ¼ãƒ«ã‚’è¦‹ç›´ã—ã€æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®èªè­˜ã‚’æ”¹å–„"
        
        elif field == "currency":
            # ä»–ã®é‡‘é¡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰æ¨æ¸¬ï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
            if result.get("amount_inclusive_tax") or result.get("amount_exclusive_tax"):
                return "é‡‘é¡ã¯å–å¾—ã§ãã¦ã„ã‚‹ãŸã‚ã€é€šè²¨ã¯JPYã¨æ¨å®šã€‚è‡ªå‹•è£œå®Œãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ "
            return "PDFã‹ã‚‰é€šè²¨è¡¨è¨˜ã‚’ç¢ºèªã—ã€é€šè²¨ã‚³ãƒ¼ãƒ‰æŠ½å‡ºã®æŒ‡ç¤ºã‚’å¼·åŒ–"
        
        return "å€‹åˆ¥ç¢ºèªãŒå¿…è¦ã§ã™"

    def create_correction_workflow(self, error_files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®æ­£ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ"""
        workflow = {
            "total_errors": len(error_files),
            "correction_plan": {
                "prompt_adjustments": [],
                "manual_reviews": [],
                "system_improvements": []
            },
            "priority_order": []
        }
        
        for error_file in error_files:
            result = error_file["ocr_result"]
            validation = error_file["validation"]
            analysis = self.analyze_error_details(result, validation)
            
            file_info = {
                "filename": error_file["filename"],
                "completeness_score": validation["completeness_score"],
                "analysis": analysis,
                "priority": "high" if analysis["manual_review_needed"] else "medium"
            }
            
            workflow["priority_order"].append(file_info)
            
            # ä¿®æ­£ææ¡ˆã‚’åˆ†é¡
            for suggestion in analysis["correction_suggestions"]:
                if suggestion["type"] == "prompt_improvement":
                    workflow["correction_plan"]["prompt_adjustments"].append({
                        "file": error_file["filename"],
                        "suggestion": suggestion
                    })
                elif suggestion["type"] == "data_validation":
                    workflow["correction_plan"]["system_improvements"].append({
                        "file": error_file["filename"],
                        "suggestion": suggestion
                    })
            
            if analysis["manual_review_needed"]:
                workflow["correction_plan"]["manual_reviews"].append(file_info)
        
        # å„ªå…ˆé †ä½ã§ã‚½ãƒ¼ãƒˆï¼ˆå®Œå…¨æ€§ã‚¹ã‚³ã‚¢ãŒä½ã„é †ï¼‰
        workflow["priority_order"].sort(key=lambda x: x["completeness_score"])
        
        return workflow

    def display_results_with_aggrid(self, test_results: Dict[str, Any]) -> None:
        """ag-gridã‚’ä½¿ã£ã¦ãƒ†ã‚¹ãƒˆçµæœã‚’è¡¨ç¤º"""
        try:
            from infrastructure.ui.aggrid_helper import get_aggrid_manager
            
            aggrid_manager = get_aggrid_manager()
            if not aggrid_manager:
                st.warning("ag-gridãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä»£æ›¿è¡¨ç¤ºã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                return
            
            # çµæœãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
            results_data = []
            for result in test_results.get("results", []):
                ocr_result = result["ocr_result"]
                validation = result["validation"]
                
                # å®Œå…¨æ€§ã‚¹ã‚³ã‚¢ã®å®‰å…¨ãªå¤‰æ›
                completeness_score = validation.get('completeness_score', 0)
                if isinstance(completeness_score, (int, float)):
                    completeness_score = float(round(completeness_score, 1))
                else:
                    completeness_score = 0.0
                
                # ç¨è¾¼é‡‘é¡ã®å®‰å…¨ãªå¤‰æ›ï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
                tax_included = ocr_result.get("amount_inclusive_tax", 0)
                if not isinstance(tax_included, (int, float)):
                    try:
                        tax_included = float(tax_included) if tax_included else 0
                    except (ValueError, TypeError):
                        tax_included = 0
                tax_included = int(tax_included)
                
                # ã‚¨ãƒ©ãƒ¼æ•°ã¨è­¦å‘Šæ•°ã®å®‰å…¨ãªå¤‰æ›
                error_count = len(validation.get("errors", []))
                warning_count = len(validation.get("warnings", []))
                file_size = result.get('file_size', 0)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®å®‰å…¨ãªå¤‰æ›
                try:
                    file_size = int(file_size) if file_size else 0
                except (ValueError, TypeError):
                    file_size = 0
                
                results_data.append({
                    "ãƒ•ã‚¡ã‚¤ãƒ«å": str(result["filename"]),
                    "è«‹æ±‚å…ƒ": str(ocr_result.get("issuer", "")),                   # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "è«‹æ±‚å…ˆ": str(ocr_result.get("payer", "")),                    # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "è«‹æ±‚æ›¸ç•ªå·": str(ocr_result.get("main_invoice_number", "")),  # JSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆ
                    "é€šè²¨": str(ocr_result.get("currency", "")),
                    "ç¨è¾¼é‡‘é¡": tax_included,
                    "ç™ºè¡Œæ—¥": str(ocr_result.get("issue_date", "")),
                    "æ¤œè¨¼çŠ¶æ³": "âœ… æ­£å¸¸" if validation["is_valid"] else "âŒ ã‚¨ãƒ©ãƒ¼",
                    "å®Œå…¨æ€§ã‚¹ã‚³ã‚¢": completeness_score,
                    "ã‚¨ãƒ©ãƒ¼æ•°": error_count,
                    "è­¦å‘Šæ•°": warning_count,
                    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º": f"{file_size:,} bytes"
                })
            
            if len(results_data) > 0:
                df = pd.DataFrame(results_data)
                
                # é¸æŠçŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
                col_grid, col_reset = st.columns([4, 1])
                with col_grid:
                    st.subheader("ğŸ“Š OCRãƒ†ã‚¹ãƒˆçµæœ (ag-grid)")
                with col_reset:
                    if st.button("ğŸ”„ é¸æŠãƒªã‚»ãƒƒãƒˆ", key="reset_current_test_selection"):
                        current_test_key = "selected_current_test_file"
                        if current_test_key in st.session_state:
                            del st.session_state[current_test_key]
                        st.rerun()
                
                grid_response = aggrid_manager.create_data_grid(
                    df,
                    editable=False,
                    fit_columns_on_grid_load=True,
                    selection_mode="single",
                    use_checkbox=False,
                    height=400
                )
                
                # é¸æŠã•ã‚ŒãŸè¡Œã®è©³ç´°è¡¨ç¤º
                selected_rows = aggrid_manager.get_selected_rows(grid_response)
                
                # selected_rowsã®å®‰å…¨ãªå‡¦ç†
                if hasattr(selected_rows, 'to_dict'):
                    selected_rows = selected_rows.to_dict('records')
                elif not isinstance(selected_rows, list):
                    selected_rows = []
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§é¸æŠæƒ…å ±ã‚’ç®¡ç†ï¼ˆæ–°ã—ã„OCRãƒ†ã‚¹ãƒˆç”¨ï¼‰
                current_test_key = "selected_current_test_file"
                
                # æ–°ã—ã„é¸æŠãŒã‚ã‚Œã°ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                if len(selected_rows) > 0:
                    selected_row = selected_rows[0]
                    filename = selected_row["ãƒ•ã‚¡ã‚¤ãƒ«å"]
                    st.session_state[current_test_key] = filename
                # é¸æŠãŒãªã‘ã‚Œã°ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å¾©å…ƒ
                elif current_test_key in st.session_state:
                    filename = st.session_state[current_test_key]
                else:
                    filename = None
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã®è©³ç´°è¡¨ç¤º
                if filename:
                    st.markdown(f"### ğŸ“„ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
                    
                    # è©²å½“ã™ã‚‹è©³ç´°çµæœã‚’å–å¾—
                    try:
                        selected_result = next(
                            r for r in test_results["results"] 
                            if r["filename"] == filename
                        )
                    except StopIteration:
                        st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã®è©³ç´°çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                        if current_test_key in st.session_state:
                            del st.session_state[current_test_key]
                        selected_result = None
                    
                    # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆå…±é€šãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨ï¼‰
                    if selected_result is not None:
                        self.display_invoice_details(selected_result, data_type="new", show_line_items=True)
                    
        except ImportError:
            st.warning("ag-gridãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æ¨™æº–ã®DataFrameã§è¡¨ç¤ºã—ã¾ã™ã€‚")
        except Exception as e:
            st.error(f"ag-gridè¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            st.subheader("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
            st.write("**ãƒ‡ãƒ¼ã‚¿å‹æƒ…å ±:**")
            if len(results_data) > 0:
                sample_data = results_data[0]
                for key, value in sample_data.items():
                    st.write(f"â€¢ {key}: {type(value)} = {repr(value)}")
            
            # ä»£æ›¿è¡¨ç¤º
            st.subheader("ğŸ“Š ä»£æ›¿è¡¨ç¤ºï¼ˆæ¨™æº–DataFrameï¼‰")
            if len(results_data) > 0:
                df = pd.DataFrame(results_data)
                st.dataframe(df, use_container_width=True)


def display_session_history(ocr_test_manager: 'OCRTestManager', user_email: str) -> None:
    """Supabaseã‹ã‚‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’è¡¨ç¤º"""
    
    st.markdown("---")
    st.subheader("ğŸ“ˆ éå»ã®OCRãƒ†ã‚¹ãƒˆå±¥æ­´")
    
    sessions = ocr_test_manager.load_sessions_from_supabase(user_email)
    
    # DataFrameã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
    if hasattr(sessions, 'to_dict'):
        sessions = sessions.to_dict('records')
    elif not isinstance(sessions, list):
        sessions = []
    
    if len(sessions) == 0:
        st.info("éå»ã®ãƒ†ã‚¹ãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³é¸æŠ
    session_options = [
        f"{session['session_name']} ({convert_utc_to_jst(session['created_at'])}) - æˆåŠŸç‡: {session['success_rate']}%"
        for session in sessions
    ]
    
    selected_session_index = st.selectbox(
        "è¡¨ç¤ºã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é¸æŠ",
        range(len(session_options)),
        format_func=lambda x: session_options[x]
    )
    
    if selected_session_index is not None:
        selected_session = sessions[selected_session_index]
        session_id = selected_session["id"]
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°è¡¨ç¤º
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°", selected_session["total_files"])
        with col2:
            st.metric("æˆåŠŸãƒ•ã‚¡ã‚¤ãƒ«æ•°", selected_session["success_files"])
        with col3:
            st.metric("æˆåŠŸç‡", f"{selected_session['success_rate']}%")
        with col4:
            st.metric("å¹³å‡å®Œå…¨æ€§", f"{selected_session['average_completeness']}%")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœã‚’å–å¾—
        session_results = ocr_test_manager.load_session_results(session_id)
        
        # DataFrameã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
        if hasattr(session_results, 'to_dict'):
            session_results = session_results.to_dict('records')
        elif not isinstance(session_results, list):
            session_results = []
        
        if len(session_results) > 0:
            try:
                from infrastructure.ui.aggrid_helper import get_aggrid_manager
                
                aggrid_manager = get_aggrid_manager()
                if aggrid_manager:
                    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
                    history_data = []
                    for result in session_results:
                        # å®Œå…¨æ€§ã‚¹ã‚³ã‚¢ã®å®‰å…¨ãªå¤‰æ›
                        completeness_score = result.get('completeness_score', 0)
                        if isinstance(completeness_score, (int, float)):
                            completeness_score = float(round(completeness_score, 1))
                        else:
                            completeness_score = 0.0
                        
                        # ç¨è¾¼é‡‘é¡ã®å®‰å…¨ãªå¤‰æ›
                        tax_included = result.get("total_amount_tax_included", 0)
                        if not isinstance(tax_included, (int, float)):
                            tax_included = 0
                        
                        history_data.append({
                            "ãƒ•ã‚¡ã‚¤ãƒ«å": str(result["filename"]),
                            "è«‹æ±‚å…ƒ": str(result["issuer_name"] or ""),      # DBãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åï¼ˆå¤‰æ›´ãªã—ï¼‰
                            "è«‹æ±‚æ›¸ç•ªå·": str(result["invoice_number"] or ""), # DBãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åï¼ˆå¤‰æ›´ãªã—ï¼‰
                            "é€šè²¨": str(result["currency"] or ""),
                            "ç¨è¾¼é‡‘é¡": int(tax_included),
                            "ç™ºè¡Œæ—¥": str(result["issue_date"]) if result["issue_date"] else "",
                            "æ¤œè¨¼çŠ¶æ³": "âœ… æ­£å¸¸" if result["is_valid"] else "âŒ ã‚¨ãƒ©ãƒ¼",
                            "å®Œå…¨æ€§ã‚¹ã‚³ã‚¢": completeness_score,
                            "å‡¦ç†æ—¥æ™‚": convert_utc_to_jst(result["created_at"])
                        })
                    
                    if len(history_data) > 0:
                        df_history = pd.DataFrame(history_data)
                        
                        # é¸æŠçŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
                        col_grid, col_reset = st.columns([4, 1])
                        with col_grid:
                            st.subheader("å±¥æ­´è©³ç´° (ag-grid)")
                        with col_reset:
                            if st.button("ğŸ”„ é¸æŠãƒªã‚»ãƒƒãƒˆ", key=f"reset_selection_{session_id}"):
                                session_key = f"selected_history_file_{session_id}"
                                if session_key in st.session_state:
                                    del st.session_state[session_key]
                                st.rerun()
                        
                        grid_response = aggrid_manager.create_data_grid(
                            df_history,
                            editable=False,
                            fit_columns_on_grid_load=True,
                            selection_mode="single",
                            height=400
                        )
                        
                        # é¸æŠã•ã‚ŒãŸè¡Œã®è©³ç´°è¡¨ç¤º
                        selected_rows = aggrid_manager.get_selected_rows(grid_response)
                        
                        # selected_rowsã®å®‰å…¨ãªå‡¦ç†
                        if hasattr(selected_rows, 'to_dict'):
                            selected_rows = selected_rows.to_dict('records')
                        elif not isinstance(selected_rows, list):
                            selected_rows = []
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§é¸æŠæƒ…å ±ã‚’ç®¡ç†
                        session_key = f"selected_history_file_{session_id}"
                        
                        # æ–°ã—ã„é¸æŠãŒã‚ã‚Œã°ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                        if len(selected_rows) > 0:
                            selected_row = selected_rows[0]
                            filename = selected_row["ãƒ•ã‚¡ã‚¤ãƒ«å"]
                            st.session_state[session_key] = filename
                        # é¸æŠãŒãªã‘ã‚Œã°ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å¾©å…ƒ
                        elif session_key in st.session_state:
                            filename = st.session_state[session_key]
                        else:
                            filename = None
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã®è©³ç´°è¡¨ç¤º
                        if filename:
                            st.markdown(f"### ğŸ“„ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
                            
                            # è©²å½“ã™ã‚‹è©³ç´°çµæœã‚’å–å¾—
                            try:
                                selected_result = next(
                                    r for r in session_results 
                                    if r["filename"] == filename
                                )
                            except StopIteration:
                                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã®è©³ç´°çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                                if session_key in st.session_state:
                                    del st.session_state[session_key]
                                selected_result = None
                            
                            # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆå…±é€šãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨ï¼‰
                            if selected_result is not None:
                                # åŸºæœ¬æƒ…å ±+æ¤œè¨¼çµæœ+æ˜ç´°ã‚’çµ±åˆè¡¨ç¤º
                                ocr_test_manager.display_invoice_details(selected_result, data_type="history", show_line_items=True)
                                
                                # ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€ä¿®æ­£ææ¡ˆã‚’è¡¨ç¤º
                                is_valid = selected_result.get("is_valid", False)
                                if not is_valid:
                                    st.markdown("---")
                                    st.markdown("### ğŸ”§ ã‚¨ãƒ©ãƒ¼ä¿®æ­£ææ¡ˆ")
                                    
                                    # raw_responseã‹ã‚‰è©³ç´°ãªãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
                                    raw_response = selected_result.get("raw_response", {})
                                    
                                    # DataFrameã®å ´åˆã¯è¾æ›¸ã«å¤‰æ›
                                    if hasattr(raw_response, 'to_dict'):
                                        raw_response = raw_response.to_dict()
                                    elif not isinstance(raw_response, dict):
                                        raw_response = {}
                                    
                                    if len(raw_response) > 0:
                                        # ç°¡æ˜“çš„ãªä¿®æ­£ææ¡ˆã‚’è¡¨ç¤º
                                        col1, col2 = st.columns(2)
                                        
                                        with col1:
                                            st.markdown("**æ¬ æã—ã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:**")
                                            
                                            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆJSONãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
                                            required_checks = [
                                                ("è«‹æ±‚å…ƒä¼æ¥­å", raw_response.get("issuer")),
                                                ("ç¨è¾¼é‡‘é¡", raw_response.get("amount_inclusive_tax")),
                                                ("é€šè²¨", raw_response.get("currency"))
                                            ]
                                            
                                            for field_name, value in required_checks:
                                                if not value:
                                                    st.write(f"âŒ {field_name}")
                                                else:
                                                    st.write(f"âœ… {field_name}: {value}")
                                        
                                        with col2:
                                            st.markdown("**æ¨å¥¨ä¿®æ­£ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**")
                                            st.write("â€¢ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´ã‚’æ¤œè¨")
                                            st.write("â€¢ ãƒ•ã‚¡ã‚¤ãƒ«å“è³ªã‚’ç¢ºèª")
                                            st.write("â€¢ æ‰‹å‹•è£œæ­£ã‚’å®Ÿæ–½")
                    else:
                        st.info("ãƒ†ã‚¹ãƒˆçµæœãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        
            except ImportError:
                st.warning("ag-gridãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æ¨™æº–è¡¨ç¤ºã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                
                # æ¨™æº–çš„ãªDataFrameè¡¨ç¤º
                if len(session_results) > 0:
                    history_df = pd.DataFrame([
                        {
                            "ãƒ•ã‚¡ã‚¤ãƒ«å": result["filename"],
                            "è«‹æ±‚å…ƒ": result.get("issuer_name", ""),
                            "è«‹æ±‚æ›¸ç•ªå·": result.get("invoice_number", ""),
                            "é€šè²¨": result.get("currency", ""),
                            "ç¨è¾¼é‡‘é¡": result.get("total_amount_tax_included", 0),
                            "æ¤œè¨¼çŠ¶æ³": "âœ… æ­£å¸¸" if result.get("is_valid") else "âŒ ã‚¨ãƒ©ãƒ¼",
                            "å®Œå…¨æ€§ã‚¹ã‚³ã‚¢": result.get("completeness_score", 0),
                            "å‡¦ç†æ—¥æ™‚": convert_utc_to_jst(result["created_at"])
                        }
                        for result in session_results
                    ])
                    st.dataframe(history_df, use_container_width=True)
        else:
            st.info("é¸æŠã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµæœãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


def create_ocr_test_app():
    """OCRãƒ†ã‚¹ãƒˆç”¨Streamlitã‚¢ãƒ—ãƒªã‚’ä½œæˆ"""
    
    st.title("ğŸ” OCRç²¾åº¦ãƒ†ã‚¹ãƒˆ - Gemini 2.0-flash")
    st.markdown("---")
    
    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        from infrastructure.storage.google_drive_helper import get_google_drive
        from infrastructure.ai.gemini_helper import get_gemini_api
        from infrastructure.database.database import get_database
        from infrastructure.auth.oauth_handler import get_current_user
        
        drive_manager = get_google_drive()
        gemini_manager = get_gemini_api()
        database_manager = get_database()
        
        if not drive_manager or not gemini_manager:
            st.error("Google Driveã¾ãŸã¯Gemini APIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        ocr_test_manager = OCRTestManager(drive_manager, gemini_manager, database_manager)
        
        # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
        current_user = get_current_user()
        user_email = current_user.get("email", "unknown@example.com")
        
    except Exception as e:
        st.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return
    
    # ã‚¿ãƒ–ä½œæˆ
    tab1, tab2 = st.tabs(["ğŸš€ æ–°ã—ã„OCRãƒ†ã‚¹ãƒˆ", "ğŸ“ˆ ãƒ†ã‚¹ãƒˆå±¥æ­´"])
    
    with tab1:
        # Google Driveãƒ•ã‚©ãƒ«ãƒ€è¨­å®š
        st.subheader("ğŸ“ Google Driveãƒ•ã‚©ãƒ«ãƒ€è¨­å®š")
        
        default_folder_id = "1ZCJsI9j8A9VJcmiY79BcP1jgzsD51X6E"
        folder_id = st.text_input(
            "ãƒ•ã‚©ãƒ«ãƒ€ID",
            value=default_folder_id,
            help="Google Driveã®ãƒ•ã‚©ãƒ«ãƒ€IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        if st.button("ğŸ“‹ ãƒ•ã‚©ãƒ«ãƒ€å†…PDFãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—"):
            with st.spinner("PDFãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ä¸­..."):
                pdf_files = ocr_test_manager.get_drive_pdfs(folder_id)
                
                # DataFrameã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
                if hasattr(pdf_files, 'to_dict'):
                    pdf_files = pdf_files.to_dict('records')
                elif not isinstance(pdf_files, list):
                    pdf_files = []
                
                if len(pdf_files) > 0:
                    st.success(f"{len(pdf_files)}å€‹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º
                    files_df = pd.DataFrame([
                        {
                            "ãƒ•ã‚¡ã‚¤ãƒ«å": f["name"],
                            "ã‚µã‚¤ã‚º": f.get("size", "ä¸æ˜"),
                            "æ›´æ–°æ—¥æ™‚": convert_utc_to_jst(f.get("modifiedTime", "")) if f.get("modifiedTime") else "ä¸æ˜",
                            "ãƒ•ã‚¡ã‚¤ãƒ«ID": f["id"]
                        }
                        for f in pdf_files
                    ])
                    
                    st.dataframe(files_df, use_container_width=True)
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                    st.session_state.pdf_files = pdf_files
        
        st.markdown("---")
        
        # OCRãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        st.subheader("ğŸ¤– OCRãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        # ãƒ†ã‚¹ãƒˆä»¶æ•°é¸æŠ
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.write("æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€å†…ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦OCRå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™")
            
        with col2:
            # ãƒ†ã‚¹ãƒˆä»¶æ•°é¸æŠ
            max_files = st.selectbox(
                "ãƒ†ã‚¹ãƒˆä»¶æ•°",
                options=[5, 10, 20, 50, -1],
                format_func=lambda x: "å…¨ã¦" if x == -1 else f"{x}ä»¶",
                index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5ä»¶
                help="å‡¦ç†ã™ã‚‹PDFãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¤§ä»¶æ•°ã‚’é¸æŠ"
            )
            
        with col3:
            if st.button("ğŸš€ OCRãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", type="primary"):
                if not folder_id:
                    st.error("ãƒ•ã‚©ãƒ«ãƒ€IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                else:
                    with st.spinner(f"OCRãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...ï¼ˆæœ€å¤§{max_files if max_files != -1 else 'å…¨'}ä»¶ï¼‰"):
                        test_results = ocr_test_manager.run_comprehensive_test(folder_id, max_files=max_files)
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                        st.session_state.test_results = test_results
                        
                        # Supabaseã«ä¿å­˜
                        if len(test_results.get("results", [])) > 0:
                            session_id = ocr_test_manager.save_to_supabase(test_results, user_email)
                            if session_id:
                                st.success(f"âœ… çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã—ãŸ (ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id})")
                                st.session_state.current_session_id = session_id
        
        # ãƒ†ã‚¹ãƒˆçµæœè¡¨ç¤º
        if hasattr(st.session_state, 'test_results') and len(st.session_state.test_results.get("results", [])) > 0:
            st.markdown("---")
            st.subheader("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ")
            
            test_results = st.session_state.test_results
            
            # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            if test_results.get("summary"):
                summary = test_results["summary"]
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æˆåŠŸç‡", f"{summary['success_rate']}%")
                with col2:
                    st.metric("å¹³å‡å®Œå…¨æ€§", f"{summary['average_completeness']}%")
                with col3:
                    st.metric("å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°", test_results["files_processed"])
                with col4:
                    st.metric("å‡¦ç†æ™‚é–“", f"{test_results['duration']:.1f}ç§’")
            
            # ag-gridã§ã®è¡¨ç¤º
            ocr_test_manager.display_results_with_aggrid(test_results)
    
    with tab2:
        # ãƒ†ã‚¹ãƒˆå±¥æ­´è¡¨ç¤º
        display_session_history(ocr_test_manager, user_email)


if __name__ == "__main__":
    create_ocr_test_app() 